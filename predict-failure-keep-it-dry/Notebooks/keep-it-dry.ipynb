{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import optuna\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('..\\\\Dataset\\\\raw\\\\train.csv')\n",
    "df_test = pd.read_csv('..\\\\Dataset\\\\raw\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the label/class\n",
    "label = df_train.pop('failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>loading</th>\n",
       "      <th>attribute_0</th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>measurement_0</th>\n",
       "      <th>measurement_1</th>\n",
       "      <th>measurement_2</th>\n",
       "      <th>...</th>\n",
       "      <th>measurement_8</th>\n",
       "      <th>measurement_9</th>\n",
       "      <th>measurement_10</th>\n",
       "      <th>measurement_11</th>\n",
       "      <th>measurement_12</th>\n",
       "      <th>measurement_13</th>\n",
       "      <th>measurement_14</th>\n",
       "      <th>measurement_15</th>\n",
       "      <th>measurement_16</th>\n",
       "      <th>measurement_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80.10</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.155</td>\n",
       "      <td>10.672</td>\n",
       "      <td>15.859</td>\n",
       "      <td>17.594</td>\n",
       "      <td>15.193</td>\n",
       "      <td>15.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.034</td>\n",
       "      <td>14.684</td>\n",
       "      <td>764.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>84.89</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>17.889</td>\n",
       "      <td>12.448</td>\n",
       "      <td>17.947</td>\n",
       "      <td>17.915</td>\n",
       "      <td>11.755</td>\n",
       "      <td>14.732</td>\n",
       "      <td>15.425</td>\n",
       "      <td>14.395</td>\n",
       "      <td>15.631</td>\n",
       "      <td>682.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>82.43</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>18.288</td>\n",
       "      <td>12.715</td>\n",
       "      <td>15.607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.798</td>\n",
       "      <td>16.711</td>\n",
       "      <td>18.631</td>\n",
       "      <td>14.094</td>\n",
       "      <td>17.946</td>\n",
       "      <td>663.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>101.07</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>19.060</td>\n",
       "      <td>12.471</td>\n",
       "      <td>16.346</td>\n",
       "      <td>18.377</td>\n",
       "      <td>10.020</td>\n",
       "      <td>15.250</td>\n",
       "      <td>15.562</td>\n",
       "      <td>16.154</td>\n",
       "      <td>17.172</td>\n",
       "      <td>826.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>188.06</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.093</td>\n",
       "      <td>10.337</td>\n",
       "      <td>17.082</td>\n",
       "      <td>19.932</td>\n",
       "      <td>12.428</td>\n",
       "      <td>16.182</td>\n",
       "      <td>12.760</td>\n",
       "      <td>13.153</td>\n",
       "      <td>16.412</td>\n",
       "      <td>579.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>75.35</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.810</td>\n",
       "      <td>10.622</td>\n",
       "      <td>14.904</td>\n",
       "      <td>19.107</td>\n",
       "      <td>13.327</td>\n",
       "      <td>15.354</td>\n",
       "      <td>19.251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.625</td>\n",
       "      <td>832.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>161.71</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.916</td>\n",
       "      <td>11.370</td>\n",
       "      <td>17.714</td>\n",
       "      <td>19.924</td>\n",
       "      <td>11.560</td>\n",
       "      <td>16.653</td>\n",
       "      <td>17.734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.637</td>\n",
       "      <td>684.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A</td>\n",
       "      <td>177.92</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.643</td>\n",
       "      <td>10.254</td>\n",
       "      <td>16.449</td>\n",
       "      <td>20.478</td>\n",
       "      <td>12.207</td>\n",
       "      <td>15.624</td>\n",
       "      <td>16.968</td>\n",
       "      <td>15.176</td>\n",
       "      <td>17.231</td>\n",
       "      <td>684.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>109.50</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.887</td>\n",
       "      <td>11.557</td>\n",
       "      <td>15.965</td>\n",
       "      <td>19.604</td>\n",
       "      <td>14.091</td>\n",
       "      <td>15.674</td>\n",
       "      <td>13.327</td>\n",
       "      <td>13.535</td>\n",
       "      <td>15.408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>98.72</td>\n",
       "      <td>material_7</td>\n",
       "      <td>material_8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>19.011</td>\n",
       "      <td>10.384</td>\n",
       "      <td>15.237</td>\n",
       "      <td>18.427</td>\n",
       "      <td>12.635</td>\n",
       "      <td>14.318</td>\n",
       "      <td>14.327</td>\n",
       "      <td>12.867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id product_code  loading attribute_0 attribute_1  attribute_2  attribute_3  \\\n",
       "0   0            A    80.10  material_7  material_8            9            5   \n",
       "1   1            A    84.89  material_7  material_8            9            5   \n",
       "2   2            A    82.43  material_7  material_8            9            5   \n",
       "3   3            A   101.07  material_7  material_8            9            5   \n",
       "4   4            A   188.06  material_7  material_8            9            5   \n",
       "5   5            A    75.35  material_7  material_8            9            5   \n",
       "6   6            A   161.71  material_7  material_8            9            5   \n",
       "7   7            A   177.92  material_7  material_8            9            5   \n",
       "8   8            A   109.50  material_7  material_8            9            5   \n",
       "9   9            A    98.72  material_7  material_8            9            5   \n",
       "\n",
       "   measurement_0  measurement_1  measurement_2  ...  measurement_8  \\\n",
       "0              7              8              4  ...         20.155   \n",
       "1             14              3              3  ...         17.889   \n",
       "2             12              1              5  ...         18.288   \n",
       "3             13              2              6  ...         19.060   \n",
       "4              9              2              8  ...         18.093   \n",
       "5             11              4              0  ...         20.810   \n",
       "6             12              2              4  ...         17.916   \n",
       "7              4              8              8  ...         18.643   \n",
       "8              9              6              5  ...         19.887   \n",
       "9             10              4              7  ...         19.011   \n",
       "\n",
       "   measurement_9  measurement_10  measurement_11  measurement_12  \\\n",
       "0         10.672          15.859          17.594          15.193   \n",
       "1         12.448          17.947          17.915          11.755   \n",
       "2         12.715          15.607             NaN          13.798   \n",
       "3         12.471          16.346          18.377          10.020   \n",
       "4         10.337          17.082          19.932          12.428   \n",
       "5         10.622          14.904          19.107          13.327   \n",
       "6         11.370          17.714          19.924          11.560   \n",
       "7         10.254          16.449          20.478          12.207   \n",
       "8         11.557          15.965          19.604          14.091   \n",
       "9         10.384          15.237          18.427          12.635   \n",
       "\n",
       "   measurement_13  measurement_14  measurement_15  measurement_16  \\\n",
       "0          15.029             NaN          13.034          14.684   \n",
       "1          14.732          15.425          14.395          15.631   \n",
       "2          16.711          18.631          14.094          17.946   \n",
       "3          15.250          15.562          16.154          17.172   \n",
       "4          16.182          12.760          13.153          16.412   \n",
       "5          15.354          19.251             NaN          17.625   \n",
       "6          16.653          17.734             NaN          16.637   \n",
       "7          15.624          16.968          15.176          17.231   \n",
       "8          15.674          13.327          13.535          15.408   \n",
       "9          14.318          14.327          12.867             NaN   \n",
       "\n",
       "   measurement_17  \n",
       "0         764.100  \n",
       "1         682.057  \n",
       "2         663.376  \n",
       "3         826.282  \n",
       "4         579.885  \n",
       "5         832.902  \n",
       "6         684.438  \n",
       "7         684.000  \n",
       "8             NaN  \n",
       "9             NaN  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26570, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['loading', 'measurement_0', 'measurement_1',\n",
    "       'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5',\n",
    "       'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9',\n",
    "       'measurement_10', 'measurement_11', 'measurement_12', 'measurement_13',\n",
    "       'measurement_14', 'measurement_15', 'measurement_16', 'measurement_17']\n",
    "cat_cols = ['attribute_0', 'attribute_1', 'attribute_2', 'attribute_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABC8klEQVR4nO3dd3wUdeI+8GdreichIZRAqKGD0puCFOmKHugpHU9RRLD95FRsp54KlrN/FTw8LICAYqEIQRGkhZqAhJAEEknvPdn9/P4IGQkJkLKbz87s836ZFzhsZp9JdveZ+UzTCSEEiIiIAOhlByAiIsfBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUpAkLCwMs2bNkh3jmmJjYzF69Gj4+PhAp9Nh06ZNsiNVM2vWLHh6ejbJc0VGRkKn0yEyMrJJnq+uRowYgREjRjTJc+l0Ojz44INN8lwkj0OUwurVq6HT6ZQvV1dXdOzYEQ8++CBSU1Nlx2uwvXv3Yvny5cjJyZEdpUFmzpyJEydO4KWXXsKaNWtwww031Pq4hISEar+/K79eeeWVJk5ePxs3bsS4cePQrFkzmM1mtGjRAnfeeSd27twpO1qTc4TXbFhYmPLa0ev18PX1Rffu3bFgwQLs37+/UfP+17/+5TArNzExMVi+fDkSEhJkR6nGKDvA5Z5//nm0bdsWJSUl2LNnD95//3388MMPOHnyJNzd3WXHq7e9e/fiueeew6xZs+Dr61vt3/744w/o9Q7RybUqLi7Gvn37sGzZsjqvHc6YMQO33nprjem9e/e2dTybEEJgzpw5WL16NXr37o0lS5YgODgYFy9exMaNGzFy5Ej89ttvGDRokOyoV7Vt2zabzu9ar9mm1KtXLyxduhQAkJ+fj1OnTmHdunX4+OOP8cgjj2DFihUNmu+//vUvTJs2DVOmTLFh2oaJiYnBc889hxEjRiAsLEx2HIVDlcK4ceOUtdF58+YhICAAK1aswObNmzFjxoxav6ewsBAeHh5NGfO66pLJxcWlidI0THp6OgDU64OhT58++Pvf/26nRLb3xhtvYPXq1Vi8eDFWrFgBnU6n/NuyZcuwZs0aGI0O9RapwWw2y45gF6GhoTVeS6+++iruuusurFy5Eh06dMD9998vKZ3GCQewatUqAUAcPHiw2vQtW7YIAOKll14SQggxc+ZM4eHhIc6ePSvGjRsnPD09xeTJk4UQQhQUFIglS5aIli1bCrPZLDp27Chee+01YbVaq80TgFi4cKH4/PPPRceOHYWLi4vo06eP2L17d41cUVFRYuzYscLLy0t4eHiIm2++Wezbt6/W7JGRkeL+++8XgYGBwtfXVzz77LMCQI2v+Ph4IYQQbdq0ETNnzqw2r7i4ODFt2jTh5+cn3NzcRP/+/cWWLVuqPWbXrl0CgPjqq6/Eiy++KEJDQ4WLi4u4+eabRWxsbJ1+3tdbrtqyt2nT5qrzi4+PFwDEa6+9dt3n3rRpk7j11ltFSEiIMJvNol27duL5558XFRUVNR77+++/i3HjxglfX1/h7u4uunfvLt58803l36teD0lJSWLy5MnCw8NDNGvWTCxdurTW+V2uqKhI+Pv7i86dO1/3sUL89XPftWuXMu2XX34R06ZNE61atRJms1m0bNlSLF68WBQVFVX73osXL4pZs2aJ0NBQYTabRXBwsJg0aZLyWhBCiIMHD4rRo0eLgIAA4erqKsLCwsTs2bOvm2v48OFi+PDhNXI25PVxvdds1Xtn48aNomvXrsJsNouIiAjx448/1phXUlKSmD17tggKClIe98knn1x3eYSofG+MHz++1n/Lz88X/v7+IjQ0tNp7+7XXXhMDBw4U/v7+wtXVVfTp00esW7eu2vfWtmxV78GEhARx//33i44dOwpXV1fh7+8vpk2bVu13JIQQZWVlYvny5aJ9+/bCxcVF+Pv7i8GDB4tt27ZVe9ypU6fE7bffLvz8/ISLi4vo27ev2Lx5s/LvVZ8bV35d/vqSxaFXg+Li4gAAAQEByrSKigqMGTMGQ4YMweuvvw53d3cIITBp0iTs2rULc+fORa9evbB161Y89thjSE5OxsqVK6vNd/fu3fjqq6+waNEiuLi44L333sPYsWNx4MABdOvWDQAQHR2NoUOHwtvbG48//jhMJhM+/PBDjBgxArt370b//v2rzfOBBx5AYGAgnnnmGRQWFmLcuHE4c+YMvvjiC6xcuRLNmjUDAAQGBta6rKmpqRg0aBCKioqwaNEiBAQE4LPPPsOkSZOwfv16TJ06tdrjX3nlFej1ejz66KPIzc3Fv//9b9x9993XHXOty3Lddttt8PX1xSOPPKIMCdVlh25RUREyMjJqTPf19VXWuFevXg1PT08sWbIEnp6e2LlzJ5555hnk5eXhtddeU75n+/btmDBhAkJCQvDwww8jODgYp06dwpYtW/Dwww8rj7NYLBgzZgz69++P119/HTt27MAbb7yB8PDwa65J7tmzB1lZWVi8eDEMBsN1l60269atQ1FREe6//34EBATgwIEDeOedd5CUlIR169Ypj7v99tsRHR2Nhx56CGFhYUhLS8P27dtx/vx55f9Hjx6NwMBAPPnkk/D19UVCQgK++eabBuUCGvb6uO222677mt2zZw+++eYbPPDAA/Dy8sLbb7+N22+/HefPn1fep6mpqRgwYICyYzowMBA//vgj5s6di7y8PCxevLjBy+Xp6YmpU6fik08+QUxMDLp27QoAeOuttzBp0iTcfffdKCsrw5dffok77rgDW7Zswfjx4wEAa9aswbx589CvXz8sWLAAABAeHg4AOHjwIPbu3Yvp06ejZcuWSEhIwPvvv48RI0YgJiZGGb5evnw5Xn75ZWU+eXl5OHToEKKionDLLbcAqHyPDR48GKGhoXjyySfh4eGBr7/+GlOmTMGGDRswdepUDBs2DIsWLcLbb7+Np556Cl26dAEA5U+pZLeSEH+15o4dO0R6erq4cOGC+PLLL0VAQIBwc3MTSUlJQojKNUMA4sknn6z2/Zs2bRIAxIsvvlht+rRp04ROpxNnz55VpuFSIx86dEiZlpiYKFxdXcXUqVOVaVOmTBFms1nExcUp0/7880/h5eUlhg0bViP7kCFDaqxxvvbaa9XWtC535ZbC4sWLBQDx66+/KtPy8/NF27ZtRVhYmLBYLEKIv9YEu3TpIkpLS5XHvvXWWwKAOHHiRM0f8GXqulz1WfuveuzVvi7fCrlyLVoIIe677z7h7u4uSkpKhBBCVFRUiLZt24o2bdqI7Ozsao+9fO2w6vXw/PPPV3tM7969Rd++fa+ZuerntXHjxusunxC1bynUtiwvv/yy0Ol0IjExUQghRHZ29nV/jhs3bqx1S7kurral0NDXx7VeswCE2Wyu9n46duyYACDeeecdZdrcuXNFSEiIyMjIqPb906dPFz4+PrX+3C53rS0FIYRYuXKlAFBtzfvKeZaVlYlu3bqJm2++udp0Dw+PGlvotX2/EELs27dPABD//e9/lWk9e/a8ZjYhhBg5cqTo3r278noWovJ1O2jQINGhQwdl2rp16xxm6+ByDrWnc9SoUQgMDESrVq0wffp0eHp6YuPGjQgNDa32uCvXAH/44QcYDAYsWrSo2vSlS5dCCIEff/yx2vSBAweib9++yv+3bt0akydPxtatW2GxWGCxWLBt2zZMmTIF7dq1Ux4XEhKCu+66C3v27EFeXl61ec6fP7/Ba5xVy9CvXz8MGTJEmebp6YkFCxYgISEBMTEx1R4/e/bsauPJQ4cOBQCcO3fuqs/RkOWqjwULFmD79u01viIiIpTHuLm5KX/Pz89HRkYGhg4diqKiIpw+fRoAcOTIEcTHx2Px4sU19mlcPu5f5R//+Ee1/x86dOg1fw4AlOX08vKq1zJe7vJlKSwsREZGBgYNGgQhBI4cOaI8xmw2IzIyEtnZ2bXOp2oZt2zZgvLy8gbnuVxDXh91MWrUKGXtGgB69OgBb29vZb5CCGzYsAETJ06EEAIZGRnK15gxY5Cbm4uoqKhGZajaas3Pz1emXf67yM7ORm5uLoYOHVrn57r8+8vLy5GZmYn27dvD19e32jx8fX0RHR2N2NjYWueTlZWFnTt34s4771Re3xkZGcjMzMSYMWMQGxuL5OTkei1vU3Oo4aN3330XHTt2hNFoRPPmzdGpU6caR+gYjUa0bNmy2rTExES0aNGixhu8alMsMTGx2vQOHTrUeO6OHTuiqKhI2cFaVFSETp061Xhcly5dYLVaceHCBWXTFQDatm1bjyWtKTExscaQ1JXLUDW0BVQW2eX8/PwA4KofPEDlzuP6Lld9dOjQAaNGjbrmY6Kjo/HPf/4TO3furFFAubm5AP4aNrx8ea/G1dW1xpCcn5/fNX8OAODt7Q2g+gdLfZ0/fx7PPPMMvv322xrPV7UsLi4uePXVV7F06VI0b94cAwYMwIQJE3DvvfciODgYADB8+HDcfvvteO6557By5UqMGDECU6ZMwV133dXgAxIa8vpoyHyr5l013/T0dOTk5OCjjz7CRx99VOs80tLSGpWhoKAAQPVC37JlC1588UUcPXoUpaWlyvTaViJqU1xcjJdffhmrVq1CcnIyxGU3pKz6XQKVR0hOnjwZHTt2RLdu3TB27Fjcc8896NGjBwDg7NmzEELg6aefxtNPP13rc6WlpdVY0XUkDlUK/fr1u+qx8FVcXFwc8lDOy9c0msLVtkoufzE7mpycHAwfPhze3t54/vnnER4eDldXV0RFReGJJ56A1Wqt9zwbunXWuXNnAMCJEycadHiixWLBLbfcgqysLDzxxBPo3LkzPDw8kJycjFmzZlVblsWLF2PixInYtGkTtm7diqeffhovv/wydu7cid69e0On02H9+vX4/fff8d1332Hr1q2YM2cO3njjDfz+++8NOkHPXq+P6823arn//ve/Y+bMmbU+tuoDtKFOnjwJAGjfvj0A4Ndff8WkSZMwbNgwvPfeewgJCYHJZMKqVauwdu3aOs3zoYcewqpVq7B48WIMHDhQOWFz+vTp1X6Xw4YNQ1xcHDZv3oxt27bh//7v/7By5Up88MEHmDdvnvLYRx99FGPGjKn1uapyOyqHKoWGatOmDXbs2IH8/Pxqaw9VwxFt2rSp9vjaNv3OnDkDd3d3Za3T3d0df/zxR43HnT59Gnq9Hq1atbpurrqupVRlvNrzVf17YwUGBtpkuRoqMjISmZmZ+OabbzBs2DBlenx8fLXHVQ1PnDx58rpbHg01ZMgQ+Pn54YsvvsBTTz1V73I5ceIEzpw5g88++wz33nuvMn379u21Pj48PBxLly7F0qVLERsbi169euGNN97A559/rjxmwIABGDBgAF566SWsXbsWd999N7788kvMmzevYQvZAPV5zdYmMDAQXl5esFgsdvndFRQUYOPGjWjVqpWyFb1hwwa4urpi69at1basVq1aVeP7r7Z869evx8yZM/HGG28o00pKSmo9ic/f3x+zZ8/G7NmzUVBQgGHDhmH58uWYN2+eMixrMpmuu/yN/Vnbi+OtcjfArbfeCovFgv/85z/Vpq9cuRI6nQ7jxo2rNn3fvn3VxgkvXLiAzZs3Y/To0TAYDDAYDBg9ejQ2b95c7WzD1NRUrF27FkOGDFGGH66l6lyFupwdeuutt+LAgQPYt2+fMq2wsBAfffQRwsLCqo3LN5Stlqsxzw9UX1stKyvDe++9V+1xffr0Qdu2bfHmm2/W+NnZakvI3d0dTzzxBE6dOoUnnnii1vl+/vnnOHDgQK3fX9uyCCHw1ltvVXtcUVERSkpKqk0LDw+Hl5eXMsyRnZ1d4/l79eoFANWGQppCfV6ztTEYDLj99tuxYcMGZY3+clXDsw1RXFyMe+65B1lZWVi2bJnyoWowGKDT6WCxWJTHJiQk1HrmsoeHR63LZjAYavwO3nnnnWrzBIDMzMxq/+/p6Yn27dsrv6egoCCMGDECH374IS5evFjjeS5f/sb+rO1FE1sKEydOxE033YRly5YhISEBPXv2xLZt27B582YsXry42o4xoHKsesyYMdUOSQWA5557TnnMiy++iO3bt2PIkCF44IEHYDQa8eGHH6K0tBT//ve/65Sramf2smXLMH36dJhMJkycOLHWE9uefPJJfPHFFxg3bhwWLVoEf39/fPbZZ4iPj8eGDRtsNmRmi+W6mqioqGprvlXCw8MxcOBADBo0CH5+fpg5cyYWLVoEnU6HNWvW1Hgz6vV6vP/++5g4cSJ69eqF2bNnIyQkBKdPn0Z0dDS2bt3aqJxVHnvsMURHR+ONN97Arl27MG3aNAQHByMlJQWbNm3CgQMHsHfv3lq/t3PnzggPD8ejjz6K5ORkeHt7Y8OGDTXG7M+cOYORI0fizjvvREREBIxGIzZu3IjU1FRMnz4dAPDZZ5/hvffew9SpUxEeHo78/Hx8/PHH8Pb2rvUMcXuqz2v2al555RXs2rUL/fv3x/z58xEREYGsrCxERUVhx44dyMrKuu48kpOTlddSQUEBYmJisG7dOqSkpGDp0qW47777lMeOHz8eK1aswNixY3HXXXchLS0N7777Ltq3b4/jx4/XWL4dO3ZgxYoVaNGiBdq2bYv+/ftjwoQJWLNmDXx8fBAREYF9+/Zhx44d1Q6HB4CIiAiMGDECffv2hb+/Pw4dOoT169dXO+v/3XffxZAhQ9C9e3fMnz8f7dq1Q2pqKvbt24ekpCQcO3YMQGXxGwwGvPrqq8jNzYWLiwtuvvlmBAUF1flnbRdNfrxTLa528tqVqk5Wqk1+fr545JFHRIsWLYTJZBIdOnS47slrHTp0EC4uLqJ37961HhYWFRUlxowZIzw9PYW7u7u46aabxN69e+uV/YUXXhChoaFCr9fX+eQ1X19f4erqKvr163fVk9euPDGn6rDQVatW1Zqjvstly0NSL1/O3377TQwYMEC4ubmJFi1aiMcff1xs3bq11kPz9uzZI2655RblJLsePXpUO/Txaq+HqpOw6mr9+vVi9OjRwt/fXxiNRhESEiL+9re/icjISOUxtR2SGhMTI0aNGiU8PT1Fs2bNxPz585VDNKt+DxkZGWLhwoWic+fOwsPDQ/j4+Ij+/fuLr7/+WplPVFSUmDFjhmjdurVwcXERQUFBYsKECdUOm76aqx2S2pjXx9Ves1XvnSvV9lpOTU0VCxcuFK1atRImk0kEBweLkSNHio8++ui6z9+mTRvltaPT6YS3t7fo2rWrmD9/vti/f3+t3/PJJ58o7+fOnTuLVatW1fo6OH36tBg2bJhwc3Or9trMzs4Ws2fPFs2aNROenp5izJgx4vTp0zWW7cUXXxT9+vUTvr6+ws3NTXTu3Fm89NJLoqysrNrzxMXFiXvvvVcEBwcLk8kkQkNDxYQJE8T69eurPe7jjz8W7dq1EwaDwWEOT9UJ4cB7Ju1Ap9Nh4cKFNYaaiIhII/sUiIjINlgKRESkYCkQEZFCE0cf1YeT7UIhIqoXbikQEZGCpUBERAqWAhERKVgKRESkYCkQEZGCpUBERAqWAhERKVgKRESkcLqT14jIeVksFpvdB9vRmEymRt0nvgpLgYg0TwiBlJQUh7uhja35+voiODi4UXd1YykQkeZVFUJQUBDc3d0d9laYDSWEQFFREdLS0gAAISEhDZ4XS4GINM1isSiFcOWd1LTEzc0NAJCWloagoKAGDyVxRzMRaVrVPgR3d3fJSeyvahkbs9+EpUBETkFrQ0a1scUyshSIiEjBUiAiIgV3NBORUwp78vsmfb6EV8Y36fM1FLcUiIgc2LvvvouwsDC4urqif//+OHDggF2fj6VAROSgvvrqKyxZsgTPPvssoqKi0LNnT4wZM0Y5H8EeWApERA5qxYoVmD9/PmbPno2IiAh88MEHcHd3x6effmq352QpEBE5oLKyMhw+fBijRo1Spun1eowaNQr79u2z2/OyFIiIHFBGRgYsFguaN29ebXrz5s2RkpJit+dlKRARkYKlQETkgJo1awaDwYDU1NRq01NTUxEcHGy352UpEBE5ILPZjL59++Lnn39WplmtVvz8888YOHCg3Z6XJ68RETmoJUuWYObMmbjhhhvQr18/vPnmmygsLMTs2bPt9pwsBSJySmo4w/hvf/sb0tPT8cwzzyAlJQW9evXCTz/9VGPnsy3phBDCbnMnIpKspKQE8fHxaNu2LVxdXWXHsStbLCv3KRARkYKlQERECpYCEREpWApERKRgKRARkYKlQERECpYCEREpWApERKRgKRARkYKXuSAi57Tcp4mfL7dpn6+BuKVAROSgfvnlF0ycOBEtWrSATqfDpk2b7P6c3FIgzcktKkdeSTkKSitQWFqB/Et/FpRUoKC0Qple+acFViFg0Osqv3Q65e+uJgNcTXq4mQyX/m6At5sJQV4uCPZ2RXNvV7iZDbIXlzSssLAQPXv2xJw5c3Dbbbc1yXOyFEh1isssOJ9VhAtZRZV/Zlf+/UJWMS5kF6GozNJkWbxcjWju7Yrm3i6X/nRFc6/Kv4f4uqFDkCc8XPg2o4YZN24cxo0b16TPyVcrOazc4nKcSMrFsaQcnEnNV4ogo6BMdjRFfkkF8ksKcDatoNZ/1+mA1v7u6BzshS4h3ugc7I2IEG+08neDTqdr4rRE18dSIIdQWmFB9J95OH4hB8eScnHsQg7iMwuh9gu7CwEkZhYhMbMIW6P/uq2ip4sRnYK90DnYC51DKouie6gPzEbu5iO5WAokRUJGIQ4kZOHYhRwcT8rF6ZQ8lFtU3gD1UFBagcOJ2TicmK1MczMZcEOYHwa3b4bB4c3QtYU39HpuTVDTYilQkygorcDesxnYfSYdv8Sm40JWsexIDqe43IJfYzPwa2wGAMDX3YQBbQMwuH0ABrdvhnaBnpITkjNgKZDdxGcUYntMCn4+lYao89lOtSVgCzlF5fgpOgU/RacAAEJ8XDEovBmGdAjATZ2C4OtulpyQtIilQDZjtQocuZCN7TFp2B6Tgrj0QtmRNOVibgk2RCVhQ1QSjHodBoYHYHz3EIzpGgw/DxaEFhUUFODs2bPK/8fHx+Po0aPw9/dH69at7fKcvEczNVpCRiHWH07CN1FJ+DO3RHYcp1NVEBN7tMDY7sHwdjXJjuRQ1HyP5sjISNx00001ps+cOROrV6+uMd0Wy8pSoAYpLK3A9ycuYv2hJBxIyJIdhy5xMeoxqktzTOkdihGdAmEy8GgmNZdCfdliWTl8RHUmhMD++CysO5SEH09ebNKTxKhuSius+P7ERXx/4iL8PcyY2CME9wwMQ/sg7qSmumEp0HUl5xRjw+EkrD+chPNZRbLjUB1lFZbhs32J+O/viRjaIRBzBodheMdAnjRH18RSoKs6npSD9yPjsDU6BVYOMqqWEMAvZ9Lxy5l0hAd6YNbgtpjWpyWv20S14j4FqmFPbAbe330Wv53NlB2F7MTHzYTp/Vph5sAwtPB1kx3HrrhPoX64pUAAKg8n3Rqdgg92x+FYkjqu+04Nl1tcjg93n8Mnv8ZjTNdgzBkShr5t/GXHsiur1So7gt3ZYhm5peDkyiqs2HgkCR/+cg7neF6BU+vf1h+Pj+2Mvm38ZEexKavVitjYWBgMBgQGBsJsNmtuv4oQAmVlZUhPT4fFYkGHDh2g1zfsyDOWgpMqKqvA2v3n8cmeeFzkuQV0mVFdmuPxsZ3QsbmX7Cg2U1ZWhosXL6KoSNsHSri7uyMkJARmc8NPZmQpOBkhBNYdTsLrW/9AWn6p7DjkoPQ6YErvUCy5pSNa+rnLjmMTQghUVFTAYtHmodQGgwFGo7HRW0EsBSey/1wmXvg+BieT82RHIZUwG/W4u39rPHhTewR4usiOQ02ApeAEzmcW4V8/nFIurEZUX54uRswd0hbzh7WDJ+8kp2ksBQ3LLynHf3aexaq9CSir0P6RF2R/AR5mLB3dCTP6tdLczlqqxFLQIItV4MuD57Fy+xmHunUlaceNYX54+bbuaB+knZ3RVImloDEH4rPw9KaT+CM1X3YU0jizQY/7R4Rj4U3teRtRDWEpaERhaQVe/ek01vyeqPr7GpO6tA/yxMu3dceNYdo++c1ZsBQ0YE9sBp785jiSsnmLS5JDpwNm9GuNJ8d15v0cVI6loGL5JeV4ccspfHXoguwoRACA5t4uWD6xK8Z1D5EdhRqIpaBSv5/LxNKvjyE5h1sH5HhGRzTHv27rjmY8t0F1WAoqU1phwetb/8Ane+J5OWtyaIFeLlhxZ08M7RAoOwrVA0tBRU5dzMMjXx3F6RQeWUTqoNMBC4a1w6OjO/HWoCrBUlCJ9YeTsGzjCZTyJDRSoV6tfPHOjN5o5a+N6yhpGUvBwZVbrHhhSwz+uy9RdhSiRvF2NeL1O3pidNdg2VHoGlgKDiwtvwQL/xeFgwnZsqMQ2UTVcNLjYzrDoOdlMhwRS8FBRZ3Pxv2fH0ZqHi9vTdozoJ0/3pnRB4FePDrJ0bAUHND/9ifiuW9jUGbh/gPSriAvF3x87w3o2cpXdhS6DEvBgZRWWPDs5mh8eZAno5FzcDMZ8M6M3hgV0Vx2FLqEpeAgLuYW4x+fR+HYhRzZUYialEGvw/KJEbhnYJjsKASWgkM4k5qPez7Zz/0H5NTuG94OT47tzPs0SMZSkOzI+WzMXn0QOUXlsqMQSTepZwu8fkdPXopbIpaCRHtiM7BgzSEUlWnzRuJEDdG/rT8+uvcG+LjxaqsysBQk+fHERTz85VEeYURUiw5Bnlg9px9Cfd1kR3E6LAUJvjp4Hk9tPAkLr2hHdFVBXi74dNaN6BbqIzuKU2EpNLEPd8fh5R9Py45BpAperkasnTcA3VuyGJoKS6EJvfLjaXywO052DCJV8XEzYe38/ujagsXQFFgKTUAIgWWbTmLt/vOyoxCpkr+HGV/MH4BOwV6yo2gej/tqAsu/jWYhEDVCVmEZ7v6//TibViA7iuaxFOxs5fYz+IyXvSZqtIyCUtz18e+IzyiUHUXTWAp29NneBLz1c6zsGESakZZfWQznM4tkR9EsloKdbD6ajOXfRcuOQaQ5F3NLMOPj35GcUyw7iiaxFOxg1x9peHTdMXAXPpF9JOcU466Pf0dKbonsKJrDUrCxQwlZuP/zwyi3sBGI7Ckxswj3fLIf+SW8bpgtsRRs6HRKHuasPoiScl66gqgpxKYV4KEvjvDqADbEUrCR85lFuPeTA8grqZAdhcipRP6Rjpe+PyU7hmawFGwgt6gcM1cdQFo+74dAJMOnv8XjiwM8F8gWWAqNZLEKPPTlER47TSTZM5tPYl9cpuwYqsdSaKRXfzqNX86ky45B5PTKLQL3/+8wEriC1igshUbYfDQZH/1yTnYMIrokp6gccz87iDwekdRgLIUGOpmciyc2HJcdg4iuEJdeiAfX8oikhmIpNEBuUTn+8flhHnpK5KB+OZOOF7bEyI6hSiyFehJCYMnXR5GUzVPsiRzZ6r0J+O7Yn7JjqA5LoZ7ei4zDz6fTZMcgojp46psTuJDFi+fVB0uhHvaezcCK7WdkxyCiOsovrcBDXxxBhYVDvXXFUqij7MIyPPzVUe68IlKZoxdy8Po2rszVFUuhjp79NhrpPGOZSJU+/CUOv53NkB1DFVgKdfDTyYv4ljusiFRLCODRdceQW8zzF66HpXAdWYVl+Oemk7JjEFEjXcwtwTOb+V6+HpbCdTy9+SQyCspkxyAiG9h89E8epnodLIVr+OHERXx//KLsGERkQ//cdBKpebxj29WwFK4is6AUT3PYiEhzcovLsWzjCdkxHBZL4Sqe3nwSmYUcNiLSoh2n0vDzqVTZMRwSS6EW3x37Ez+cSJEdg4js6LnvYlBSbpEdw+GwFK6QWVCKZ7+Nlh2DiOzsfFYR3o+Mkx3D4bAUrrBi+xlkcdiIyCl8sDsO5zN5baTLsRQucyY1H18evCA7BhE1kdIKK5Z/x5GBy7EULvPi96d4bSMiJ7PzdBq2x3CncxWWwiWRf6TxXstETuq576K50/kSlgIAi1Xgpe9PyY5BRJIkZRfjPe50BsBSAACsPXAesWkFsmMQkUQf7o5DYmah7BjSOX0p5JWU403eOIfI6ZVWWPHa1j9kx5DO6Uvh3Z1neeYyEQGovN5ZbGq+7BhSOXUpXMgqwqq9CbJjEJGDsArgrZ9jZceQyqlL4dWfTqOsgvduJaK/OPvWgtOWwrn0AvxwgpfFJqLqnH1rwWlL4cPd58Dz1IioNs68teCUpZCaV4KNR5JlxyAiB+XMWwtOWQqf7olHmYX7Eojo6px1a8HpSiGvpBxr95+XHYOIHJyzbi04XSms2ZeI/NIK2TGISAWccWvBqUqhpNyCVb8lyI5BRCphFcAHu8/JjtGkjLIDNKUNUUnIKCiVHeOakt6fA0teWo3pnr3HI2D0/bAUZCM78lMUJxyBKCuGyb8lvAfeCY9Ogxs8z8sJIZC2bjlK4g8jcOoyuHccCACwFOcj8/sVKDl/Aka/Fmh268MwNw9Xvi9z2/sw+TaHd7/bGrroRA5py/E/8cyECPi4m2RHaRJOUwpWq8DHvzh+44fMXAlY/9oJXpaRiLSv/gmPzpUf+hnfr4C1tABBtz0NvbsPCmMikbH5VZhmrqz2IV2feV4u/9BmQFdzHrn7voK1rBghs95C/pEfkPnTOwiZ+SYAoDT5NMou/gH/UQsaseREjqm0wop1hy9g3tB2sqM0CacZPvrxZAoSVHDbPYO7DwyefspX8dkDMPqGwKVVdwBAafIpePWZCJcWnWDyDYbvoOnQu3igNOVsg+dZpSz1HPIObESzcYtrzKM88wI8ugyDyT8UXj3Hojyz8g51wlKBzG3vwn/0Quj0Btv9IIgcyNoDznNwitOUwuq98bIj1JuwlKMwJhKePW6BTle5+u4S2gVFp3+FpTgfQlhRGLMbwlIG19bdrzO3q88TAKzlJcj47jX4j74fBk+/Gt9nDmqLksTjEFYLiuOjYAoMAwDk7d8A11bd4RLSofELTOSgzqUXYu/ZDNkxmoRTlEJcegEOJmTLjlFvRWd+h7WkAB7dRirTAic/AWGpQNLbM3D+9anI3PouAqcug8mvRYPnCQDZP/8fXEK7wL3DgFq/z2fAHYDegOQP56Eodh8Cxj2M8qxkFJz8GT6DpyNz63+Q/MFcpG96BdZSXpOetOd/TnIou1PsU/j64AXZERqk4Pg2uLXrC6NXgDIt59fPYS0tRNDfXoTB3RtFZ35H+uZXEXz3qzBfWnuv7zyLYvej5PwxhMx6+6rfp3fxQOCkx6pNS/niKfjdNAeF0ZGoyElFi/kfIvOnd5Dz2xfwv3le/ReYyIFti0lBen4pAr1cZEexK81vKZRbrNgQpb5LWlTkpqEk8Rg8e45RppVnX0R+1BYEjHsYbmG9YA5qB98hd8EluD3yo7Y0aJ4AUJJ4DBXZKbjw5t+Q+O9JSPz3JABA+qaXkbL2yVrnVXB8O/SuHnDvMAAlF07AvcMA6AxGuHcegtLzJxqx5ESOqdwi8PUhda5g1ofmtxR+PpXq8Ieh1qbgxHYY3H3gFn6jMk1UVC6HTndFl+v0gLj+1f1qmydQOTTk2XN0tWkXP30QfjfPg1v7fjXmYynKRc7eLxF896uVE6xWCOulEwItFRCClxAhbVq7/zzuHx4Ovb6WQ/Q0QvNbCusOJcmOUG9CWFFwYgc8uo2sdkSPyb8ljH4hyNz6H5T++QfKsy8i78A3KEk4Wm1fQOqXTyHv8Hd1micAGDz9YA4Mq/YFAEbvQJh8g2vky/r5I3jfOAVGr2YAAJeWXVAYvQvlGReQf+wnuIRG2OpHQeRQknOKEXmm5jk/WqLpUsgsKMXuM+myY9RbScJRWPLS4dnjlmrTdQYjgqYth8HdB2kbXsDFVQ+i4OROBIx/pNraf3l2CqzFeXWaZ30VnzuMiuyL8OozXpnm1WcCjD7BuLhmCWCpgO/gGY16DiJHpvVrp+mEqMO4g0qt/i0ey7+LkR2DiDTEqNfh0D9HwdfdLDuKXWh6S2Hj0T9lRyAijamwCmyNTpEdw240Wwrn0gtw7EKO7BhEpEFbjmv3Vr6aLYXN3EogIjvZF5eJ7MIy2THsQrOlsD0mVXYEItKoCqvAthhtDiFpshRS80oQczHv+g8kImqgH06wFFQj8g9tH0dMRPLtO5eJQg3exVGTpbDrtPrOTSAidSmrsOIXFZ4HdT2aK4VyixW/OcklbolILi3uu9RcKRxMyEK+BjfpiMjx7PojDRarts7/1VwpRP6hvc05InJM2UXlOJyovnu1XIvmSmHXae5kJqKmsy8uU3YEm9JUKSRlFyE2rUB2DCJyIocSs2RHsClNlcIuDh0RURM7cj5HU/sVNFUKu1kKRNTECkorEPOndk6W1VQpRJ3X1g4fIlKHgwnaGULSTClcyCpClkYvUEVEjo2l4ICOJ+XKjkBETupggnZGKTRUCjmyIxCRk8ooKEV8RqHsGDahmVI4xlIgIom0MoSkiVIQQiA6WTt7/4lIfQ6xFBxHXHohr3dERFId0sh+BU2UAvcnEJFs8ZmFKCm3yI7RaBopBR55RERyCQHEpav/MjuaKAXuZCYiRxCXrv4jkFRfChUWq6ZOMSci9YrTwAU5VV8KSdnFKK2wyo5BRMThI0eQlF0sOwIREQAOHzmEC9lFsiMQEQEA4jMKIIS6L6Ot/lLIYikQkWMoKbciOUfdoxeqLwUOHxGRI1H7EJLqS4HDR0TkSNR+BJL6SyGLWwpE5DjUfgSSqkuhpNyCjIJS2TGIiBRqH9JWdSkkceiIiBxMTpG67wCp6lLg0BEROZosloI83FIgIkeTXVguO0KjqLoUUvJKZEcgIqqmoLQCZSq+9I6qSyG3WN2NTETalK3iISRVl0JeMe+2RkSOJ6uQpSBFXgm3FIjI8WSzFOTI4/ARETmg7CL1fjapuhTySzh8RESOR82Hpaq6FApLWQpE5Hg4fCRJiYoP+yIi7VLzkZHqLoVyi+wIREQ1lFvUu8LKUiAisjGLVb13X1NtKZRWWKDinzsRaZhVxbfkVHEpqHfzjIi0rcLCUmhyRr1OdgQiolpZVLylYJQdoKHMBtX2GTmgcPdibPFbKTsGaUSZ5y0AesmO0SCqLQWjQQ+DXqfqHTrkOOKK3GB2z4Kh4E/ZUUgD3Fr1lB2hwVS9us2tBbKli769ZUcgrdAbZCdoMFV/qpqNqo5PDiYKnWVHIK3Qq3YQhqVAVGVLTpjsCKQVLAU5OHxEtrQ90x9WVz/ZMUgLdBw+ksKFWwpkQ0LokOHfR3YM0gKjWXaCBlP1pyqHj8jWThgiZEcgLXAPkJ2gwVT9qcpSIFv7Kb+t7AikBR6BshM0mKo/VblPgWzt27QgCJOH7Bikdu7NZCdoMFV/qvq4mWRHII0pteqRG6DeE4/IQXiwFKRo7uMqOwJpUIypm+wIpHYsBTmCvVkKZHs/F4XLjkBqx30KcrAUyB7Wp4VA6Dk0SQ1k8gBMbrJTNJiqS4HDR2QPueVGFAZwCIkaSMVDR4DKS4FbCmQvZ127y45AasVSkIelQPayu7Sj7AikVirenwCovBR83E1wNal6EchBrUsLhQDv7kcNwC0Fubi1QPaQVOKCUv9OsmOQGnFLQa7mLAWykwQPnsRGDeCv7kOaVV8KwTwCiexkbwX3K1ADBHWRnaBRVF8Kob7qPR6YHNuGjNayI5Dq6IBAdd/BT/Wl0DnEW3YE0qjofA+Ue7eRHYPUxKcV4OIpO0WjqL4UIkK8ZEcgDUvy7i07AqlJkLq3EgANlELbZp68AxvZzUHBI5CoHlQ+dARooBQMeh06BXNrgezj2+ww2RFITYLUf+c+1ZcCAERwvwLZyZ4sH1g8gmTHILXg8JFj6MJSIDtK9e0jOwKpgg5opv7hRpYC0XUc1an7uHNqIn5tALO77BSNpolS6MwjkMiOvs9tKzsCqYEG9icAGikFb1cTWvrxJDayj58y/CFcuDVK16GBI48AjZQCwCEksh+L0CPLn+cr0HW0vFF2ApvQTCl0bcFSIPs5YewqOwI5Mp0BCBssO4VNaKYU+oX5y45AGratoJ3sCOTIQnoArj6yU9iEZkqhTxs/mHlmM9nJ5rRgCCOvyEtX0XaY7AQ2o5lPUVeTAb1a+cqOQRpVaNEjP4D3V6CrYCk4pgHtAmRHIA07be4mOwI5Ir0JaD1Qdgqb0VQpDGQpkB3tKlH3HbXITkL7AmYP2SlsRlOl0KeNL9xMBtkxSKPWp4ZC6Pj6oitoaOgI0FgpuBgN6N+ORyGRfaSXmVAcwENT6Qpth8pOYFOaKgUAGN4xUHYE0rA4t+6yI5AjMboCrfrLTmFTmiuFYSwFsqNfyzrKjkCOpFU/wOgiO4VNaa4UwgM9eR0kspv16a0goJMdgxyFxvYnABosBQAY0YlbC2Qf54pcUe7XXnYMchSdJ8pOYHOaLIVbu4fIjkAalujJk9gIQFBXTdxp7UqaLIUBbQPQ3Ftb43zkOH6vUP/dtcgGut8uO4FdaLIU9HodJvRoITsGadTGrDayI5Aj6MZSUJXJvVgKZB9RuZ6o8AqVHYNkankj4BcmO4VdaLYUerT0Rbtm2jn1nBzLnz686Y5T6zZNdgK70WwpAMDEntxaIPs4JLrIjkCy6PRA16myU9iNUXYAe5rUqwXe+jlWdgzSoC05YbhNcoaXfy3FN6fLcTrDCjejDoNaGfDqKBd0avbX9Zk+OlyGtSfKEXXRgvwyIPsJL/i6Xvs8i7rMFwD2XajAsp2l2J9sgUEH9Ao2YOvf3eFm0qG0QmDedyXYfLocwZ56vDfeFaPa/fVx89pvpTifa8U7t6rwnKKwIYBXc9kp7EbTWwrhgZ7oFsrbdJLt7cz0g9WtmdQMuxMrsPBGM36f64Ht97ij3AqM/rwIhWVCeUxRucDY9kY8NbTuR+PVZb77LlRg7P+KMDrciAPzPHBwvgce7GeG/lLffHS4HIf/tGDfXA8s6GvCXRuKIUTl98dnW/FxVDleGqnSmxZpeOgI0PiWAgBM7hmKk8l5smOQBqX59UZw8XZpz//T36vvM1s92RVBrxfg8EULhrWpfGsvHlBZBpEJFTad7yNbS7GonxlPDvmrbC7fkjiVYcGkTkZ0DTKgnZ8ej20vRUaRQKCHDvd/X4xXR7nA20WFZ4YbzEDEJNkp7ErTWwpA5X4FvQpfe+T4jusda79Cbmnln/5utn3BXznftEIr9idbEOShx6BPCtH89XwMX12IPef/Kp6ezQ3Yc96C4nKBrXEVCPHUoZm7Dv87Xg5Xow5Tu5hsmrHJhI8E3Pxkp7ArzZdCsI8rBobz5jtkez/lt5MdQWEVAot/KsHgVgZ0C7LdPR9qm++5bCsAYPnuUszvY8JPd7ujT7ABI/9bhNhMCwBgTm8TejbXI+K9Arz0aym+vsMN2SXAM5EleGecK/65swTt387HmM8LkZxntVleu+txp+wEdqf5UgCAWYPayo5AGvRdeiCEg9xxa+H3JTiZZsGX02y747a2+Vov7Vq4r68Js3ub0TvEgJVjXdEpQI9Pj5QDAEwGHd4d74b4h71wcL4nhrQ2Yum2EizqZ8aRFAs2na7AsX94YkCoAYt+KrFpZrvxbgl00fbQEeAkpTCycxDCAtxlxyCNKbfqkO0v/3yFB38oxpbYCuya6YGW3rZ7S19tviGelX+PCKz+XF0C9Th/lbX+XfEViE6z4MF+ZkQmWHBrByM8zDrc2dWEyASLzTLbVf8FgEHzu2GdoxT0eh1mDQqTHYM0KMYk705sQgg8+EMxNp6uwM573dHWzzZv5+vNN8xXhxZeOvyRUb0AzmRa0canZoaSCoGFP5TgwwluMOh1sFiB8ks9UG4FLFZR43scjtkT6DNTdoom4RSlAAB33NAKXq7ab3lqWjsKw6U998IfSvD58XKsvc0NXi46pBRYkVJgRXH5Xx+yKQVWHE2x4GxW5Qf4iVQLjqZYkFX812NG/rcQ/zlQVuf56nQ6PDbIjLcPlGF9TDnOZlnx9M4SnM6wYm5vc42cL+wuxa0djOgdUrlPYnBrA745XY7jqRb850AZBrdWwfuy192Am6/sFE1CBb8N2/BwMWL6ja3w8a/xsqOQhmxIC8azLmboLGXXf7CNvX+ocvx+xGdF1aavmuyKWb0qP5w/OFSG53b/lW3Y6qIaj4nLsiKj6K+1/rrMd/EAF5RUAI9sLUFWsUDP5gZsv8cd4f7V1zNPplnwdUwFjt73176XaRFGRCYYMXRVIToF6LH2dgcf2tXpgQH/kJ2iyehE1RklTiApuwjDX4tUx+YqqcaJ1ivglXZIdgyyl07jgRlrZadoMk4zfAQALf3cMaardk9PJzliXbvJjkD2NHCh7ARNyqlKAQDmDuHhqWRbkSW8PadmhfQCwgbLTtGknK4U+rbxR89WvrJjkIasS2sJoXO6t5JzcLKtBMAJSwEA5gwOkx2BNORiiRkl/o51yQuyAa8QTV8i+2qcshQm9GiB9kGesmOQhsS795AdgWyt/32AQaXXaGoEpywFg16HR0fz5utkO7+Vd5AdgWzJMxjot0B2CimcshQAYGy3YPRu7Ss7BmnEuvQ2siOQLY14EnCQ61o1NactBQB4Ymxn2RFII84UuqHcx3GumkqN0KwT0Ode2SmkcepSGNAuACM6BcqOQRpxwaun7AhkC6OWA3rbXX5cbZy6FIDKrQXehIds4YCVW56q12Yw0PlW2SmkcvpS6BLijcm9QmXHIA3YmMX9Cqp3ywuyE0jn9KUAAEtu6QizgT8Kapz9Od6weATLjkENFTEFaNlXdgrp+EkIoJW/O+7q31p2DNKAFF/5N92hBtCbgFHPyk7hEFgKlzx0c3t4ujjNlcTJTqJ0EbIjUEPcMAfw59FjAEtBEeDpgodH8gQkapzvc8NkR6D6cvEGhj8hO4XDYClcZvbgMHQJ8ZYdg1Rsa4Y/rK6+smNQfQxdAngEyE7hMFgKlzEa9HhpajceokoNJoQOmX7cr6AaIT2BgQ/JTuFQWApX6NPaDzP6caczNdwJY1fZEagu9CZg8nuAgfsSL8dSqMXjYzsj0MtFdgxSqa0F3GGpCsMeBYJ517wrsRRq4eNmwguTubZHDfNtWiCEycFvRu/smncHhi6VncIhsRSuYmy3EIzvHiI7BqlQscWAPH/eX8Fh6Y3AlHed8l4JdcFSuIbnJneFv4dZdgxSoVPm7rIj0NUMeaRyBzPViqVwDc08XfDsRJ6MRPW3szhcdgSqTVAEMOxx2SkcGkvhOib3CsXoiOayY5DKrEttAaHn8IRD0RmAye8CRm79XwtLoQ7+Pa0HQn3dZMcgFckuN6IogAcrOJRBDwGhfWSncHgshTrwdTfjP3f1hsnAs9qo7s66cb+Cw2jWCbjpKdkpVIGlUEe9W/vx9p1UL7+UdJQdgQDA6AbcsQow8tyjumAp1MO8oe24f4HqbF16KAS4dSndhBVAcw7l1RVLoZ5eu6MnWvlz/wJd3/liV5T5c2tBqj73Ar3ukp1CVVgK9eTjZsK7d/XhndqoThI8eDy8NME9gHGvyU6hOvxka4AeLX2xbHwX2TFIBfZVdJIdwTm5+gB3/hcwucpOojoshQaaOSiMl8Gg6/oms5XsCM5Hpwdu/xTwbys7iSqxFBrhldu7o20zD9kxyIEdz/NEhTcvxd6kRj4LdBglO4VqsRQawcvVhFWzbuT1keiakr17yY7gPLrfAQxZLDuFqrEUGimsmQc+mXkDXE38UVLtDlp5fkuTCOkJTHpHdgrV4yeZDfRu7Yd3ZvSBgffxpFp8mxMmO4L2eQYD09cCJh4u3lgsBRu5JaI5lvOKqlSLX7J8YXUPlB1Du9z8gHs2Aj4tZSfRBJaCDd0zMAz/GM5LJlNNaX69ZUfQJrMncPd6oDlXyGyFpWBjT4zthCm9WsiOQQ7miI7ntdicwaVyyKjlDbKTaApLwcZ0Oh3+Pa0nBoUHyI5CDuSHvHayI2iLzgBM+xRoN1x2Es1hKdiB2ajHB/f0RedgL9lRyEH8kB4A4cLXg23oKm+W02WC7CCaxFKwE29XE1bP7seT2wgAYBF6ZPlzv4JNjHsV6DVDdgrNYinYUbCPK75aMADtgzxlRyEHEG3k5ZsbbcRTQP/7ZKfQNJaCnQV5VxYDh5JoeyH3KzTKgIXAiCdkp9A8lkITCPB0wZcLBqB7qI/sKCTRN2nBEAbe/atB+twLjHlJdgqnwFJoIr7uZvxvfn/0bu0rOwpJUlhhQH5AD9kx1Gfww5WXr9DxigFNgaXQhLxdTVgztz/6hfnLjkKS/OHSXXYEFdEBY14GbnledhCnwlJoYp4uRnw2px8Gt+d5DM4osqS97AjqoDcBt30MDHxAdhKnw1KQwM1swCczb8TwjrwejrNZlxYKoTPIjuHYzJ7A3V8DPe6QncQpsRQkcTUZ8PG9N2BiT14Sw5mklZpQ4s9LXlyVRyAwawsQfrPsJE6LpSCR2ajH29N7YdHNHFJwJnHuPWVHcEx+YcCcrUALnuQnE0tBMp1OhyWjO2HFnT1hNvDX4Qz2lHWQHcHxBHcH5m4HAniVYdn4KeQgbuvTEp/P6w8/d5PsKGRnGzJayY7gWMKGArN+ADyDZCchsBQcSr+2/ti8cAjPfta42EI3lPlyjRgAMPBB4J5NgKu37CR0CUvBwbQOcMc3DwzCuG7BsqOQHZ336iU7glwuPsCdayrPUjYYZaehy7AUHJC72Yj37u6DR0d35EmcGrXf0kl2BHmCuwP3RQIRk2QnoVqwFByUTqfDgzd3wP/dewN8uZ9Bc77JaCM7ghx97gXm7gD8eXFAR6UTQgjZIejaUnJL8Oi6Y9hzNkN2FLKhs4GPwZifLDtG0zC5A+PfAHrdJTsJXQe3FFQg2McVa+b2wz/Hd4HZyF+ZVlz06SU7QtMI6ADM+5mFoBL8hFEJnU6HeUPbYfPCwejYnDft0YIo4QRnNne9DViwC2geITsJ1RFLQWW6hHjj2weHYNagMO6EVrnvcsJkR7AfsxcwYSVwxyqA96ZWFe5TULHdZ9Lx6LpjSM8vlR2FGkCnE4jzfQj64izZUWyr063Ara8DPqGyk1ADcEtBxYZ3DMTWxcNwS0Rz2VGoAYTQIcNPQ9f58QgC7lgNzPiChaBiLAWV8/cw4+N7b8Cbf+uFIC/e6lFtjhs0Mtbe++/AgweArlNlJ6FG4vCRhhSUVuDN7Wewem8CKqz8tarBtOYpeD13iewYDeffDpj4FtB2mOwkZCMsBQ2KTc3HM5ujse9cpuwodB0ueitOe9wHXXmh7Cj1ozdWXrdoxP8DTK6y05ANsRQ07Ltjf+Kl708hJa9EdhS6hiNh78Iv5TfZMeoupBcw6R0gpIfsJGQH3KegYRN7tsDOR4fjH8PDYTLw+FVHdcrUVXaEuvFtDUz5AJi/i4WgYdxScBJx6QVY/m00fo3lpTIczZzQC3gm8wnZMa7OIwgY9hjQdxZgNMtOQ3bGUnAyv8am460dsTiUmC07Cl3iY6rAUfM86CxlsqNU5+IDDH4IGPAAYPaQnYaaCEvBSf12NgNv7YjFgQSNnTilUidbvQ7P9CjZMSoZ3YD+C4DBiwF3f9lpqImxFJzc3rMZePPnWByIZznItLHDVvS+8JncEHoj0PseYPgTgHeI3CwkDW955OQGtW+GQe2bYV9cJt76+Qx+P8dykGF3aQdIO7dZb6w86WzE/wMCeJtQZ8ctBapm/7lMvLkjluc4NLFQ11Ls0c2FTlib7kndm1XuPL5hDi9LQQqWAtXqyPlsrNmXiC0nLqKsogk/qJzY6RYvwDXrlP2fqEVvoN99QLfbACMvjULVsRTomjILSvHVoQv43+/nkZxTLDuOpv3Y4Vt0ufClfWZuMAMRU4B+C4BWN9rnOUgTWApUJ1arwM7Tafjy4AVE/pHGayvZwdNtT2PuxedtO1PP4Mrhob6zAC9eTZeuj6VA9ZaWV4L1UUn4+uAFJGQWyY6jGV08i/BjxbzGz0hvBMKGVl65NGIyYDA1fp7kNFgK1GBCCOyPz8KW439iW3Qq0nizn0aLbf4UTLkJ9f9GvQloN7xyiKjzeJ5fQA3GUiCbEELgyIUcbI1OwbboVMRnqOyqnw5iV4ev0fbCpro92GAG2o24VAS3Am5+dkxGzoKlQHZxJjUf26JTsDU6FSeSc2XHUY1X2x3H3/585eoPMLgA4TdVFkGncYCbb1NFIyfBUiC7S84pxrZLWxCHz2fzENdrGOyXi/8V3199ondo5T6C9iOBjmMBV2854cgpsBSoSZVWWHAiKRcHE7JxODELhxKzkVNULjuWQ4lt/TJMQZ2AtkMry4BnGVMTYimQVEIInE0rwMGEbBxKzMKhhGycz3KeI5r0OqBTsDf6tPZF3zZ+6NvGD20CeEVSkoelQA4nLa8EhxKzcfpiHuIyCnEuvRDxGQUoKVf3sFOwtyvCgzzQPtAT7YM80T7IC91b+sDThZcgI8fBUiBVEELgz9wSnEsvwLn0wso/LxXGn7nFcJRXsVGvQ+sAd4RXffAHeiI8yBPhgR7wcuX5AuT4WAqkesVlFiTnFCE9vwyZhaXIyC9FZmEZMgpKkVNUjryScuSXVCCvuBx5JRUoKKmAQOXLXgcdLv0H3aU7luqgg06ZpoOb2QB/dzP8Pczw9zQrfw/wNMPP3YyAK6YbDbzLLakXS4GIiBRcpSEiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFCwFIiJSsBSIiEjBUiAiIgVLgYiIFP8fH8WXW/f26jkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count frequency each class\n",
    "category_counts = label.value_counts()\n",
    "size = label.value_counts()\n",
    "\n",
    "# Create Bar Chart\n",
    "plt.pie(size, autopct=\"%.2f%%\")\n",
    "plt.legend(labels=category_counts.index)\n",
    "plt.title('Proportion of Each Class in the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepo(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Drop the \"material_\" word\n",
    "    df_processed['attribute_0'] = df_processed['attribute_0'].str.replace('material_', '').astype(int)\n",
    "    df_processed['attribute_1'] = df_processed['attribute_1'].str.replace('material_', '').astype(int)\n",
    "\n",
    "    # Dropping the Non-informative Feature\n",
    "    df_processed = df_processed.drop(columns=['id', 'product_code'])\n",
    "\n",
    "    # Define Pipeline & Column Transformer\n",
    "    num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # best method so far on this dataset\n",
    "    ('scaler', StandardScaler()) # for speed up the runtime\n",
    "    ])\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_pipeline, num_cols),\n",
    "            ('cat', SimpleImputer(strategy='mean'), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform data\n",
    "    df_processed = column_transformer.fit_transform(df_processed)\n",
    "\n",
    "    # split data into feature & target\n",
    "    X = df_processed\n",
    "    y = label\n",
    "\n",
    "    # split data into train & test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # change the scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # change to array\n",
    "    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train\n",
    "    X_test = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n",
    "    y_train = y_train.to_numpy() if isinstance(y_train, pd.Series) else y_train\n",
    "    y_test = y_test.to_numpy() if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepo(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the input and output dimensions\n",
    "X_dim = X_train.shape[1]\n",
    "y_dim = label.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Accuracy, F1, ROC AUC]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for evaluation result each model\n",
    "eval_columns = ['Model', 'Accuracy', 'F1', 'ROC AUC']\n",
    "eval_results = pd.DataFrame(columns=eval_columns)\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NODE : Neural Oblivious Decision Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepObliviousDecisionTreeLayer(nn.Module):\n",
    "    def __init__(self, input_dim, num_trees, tree_depth, hidden_dim):\n",
    "        super(DeepObliviousDecisionTreeLayer, self).__init__()\n",
    "        self.num_trees = num_trees\n",
    "        self.tree_depth = tree_depth\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Define a deeper architecture with hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(tree_depth):\n",
    "            self.hidden_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            input_dim = hidden_dim \n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, num_trees)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x)) \n",
    "        \n",
    "        # Apply the output layer\n",
    "        out = torch.sigmoid(self.output_layer(x))\n",
    "        return out\n",
    "\n",
    "class NODE(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_trees, tree_depth, hidden_dim):\n",
    "        super(NODE, self).__init__()\n",
    "        self.tree_layer = DeepObliviousDecisionTreeLayer(input_dim, num_trees=num_trees, tree_depth=tree_depth, hidden_dim=hidden_dim)\n",
    "        \n",
    "        # Additional fully connected layers to make it deeper\n",
    "        self.fc1 = nn.Linear(num_trees, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tree_layer(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, num_epochs=100, learning_rate=0.001, batch_size=256):\n",
    "    # Create data loaders for batch processing\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def eval_model(model, data_loader):\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in data_loader:\n",
    "                outputs = model(batch_x)\n",
    "                y_prob = F.softmax(outputs, dim=1)\n",
    "                y_true.append(batch_y)\n",
    "                y_pred.append(y_prob)\n",
    "        \n",
    "        y_true = torch.cat(y_true).numpy()\n",
    "        y_pred = torch.cat(y_pred).numpy()\n",
    "\n",
    "        # Convert probabilities to class predictions\n",
    "        y_pred_classes = torch.argmax(torch.from_numpy(y_pred), dim=1).numpy()\n",
    "\n",
    "        # Compute accuracy and F1 score\n",
    "        accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "        f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "        # Compute AUC-ROC score for test data (binary classification)\n",
    "        if y_pred.shape[1] == 2:\n",
    "            y_prob_positive = y_pred[:, 1]\n",
    "            auc_roc = roc_auc_score(y_true, y_prob_positive)\n",
    "        else:\n",
    "            auc_roc = 'N/A'\n",
    "\n",
    "        return accuracy, f1, auc_roc\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_auc_roc_scores = []\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate AUC-ROC for the current batch (only for binary classification)\n",
    "            if outputs.size(1) == 2:\n",
    "                y_prob_batch = F.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "                \n",
    "                # Check if there is more than one class in the batch\n",
    "                if len(np.unique(batch_y.cpu().numpy())) > 1:\n",
    "                    auc_roc_batch = roc_auc_score(batch_y.cpu().numpy(), y_prob_batch)\n",
    "                    batch_auc_roc_scores.append(auc_roc_batch)\n",
    "                else:\n",
    "                    print('AUC-ROC calculation skipped for batch with only one class')\n",
    "        \n",
    "        # Calculate average AUC-ROC for the epoch\n",
    "        avg_batch_auc_roc = sum(batch_auc_roc_scores) / len(batch_auc_roc_scores) if batch_auc_roc_scores else 'N/A'\n",
    "        \n",
    "        # Print information every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0 or (epoch + 1) == num_epochs:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Avg Batch AUC-ROC: {avg_batch_auc_roc:.4f}' if avg_batch_auc_roc != 'N/A' else f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Final evaluation at the end of training\n",
    "    print('Final Evaluation:')\n",
    "    final_train_accuracy, final_train_f1, final_train_auc_roc = eval_model(model, train_loader)\n",
    "    final_test_accuracy, final_test_f1, final_test_auc_roc = eval_model(model, test_loader)\n",
    "\n",
    "    print(f'Final Train Accuracy: {final_train_accuracy:.4f}')\n",
    "    print(f'Final Train F1 Score: {final_train_f1:.4f}')\n",
    "    print(f'Final Train AUC-ROC Score: {final_train_auc_roc:.4f}' if final_train_auc_roc != 'N/A' else 'Final Train AUC-ROC Score: N/A')\n",
    "    print(f'Final Test Accuracy: {final_test_accuracy:.4f}')\n",
    "    print(f'Final Test F1 Score: {final_test_f1:.4f}')\n",
    "    print(f'Final Test AUC-ROC Score: {final_test_auc_roc:.4f}' if final_test_auc_roc != 'N/A' else 'Final Test AUC-ROC Score: N/A')\n",
    "    \n",
    "    return final_test_accuracy, final_test_f1, final_test_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_dim\n",
    "output_dim = y_dim\n",
    "NODE_model = NODE(input_dim, output_dim, num_trees=10, tree_depth=6, hidden_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadhil\\AppData\\Local\\Temp\\ipykernel_10420\\3282095067.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\fadhil\\AppData\\Local\\Temp\\ipykernel_10420\\3282095067.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5866\n",
      "Epoch [20/100], Loss: 0.5172\n",
      "Epoch [30/100], Loss: 0.5196\n",
      "Epoch [40/100], Loss: 0.5175\n",
      "Epoch [50/100], Loss: 0.5175\n",
      "Epoch [60/100], Loss: 0.5174\n",
      "Epoch [70/100], Loss: 0.5172\n",
      "Epoch [80/100], Loss: 0.5170\n",
      "Epoch [90/100], Loss: 0.5158\n",
      "Epoch [100/100], Loss: 0.5077\n",
      "Final Evaluation:\n",
      "Final Train Accuracy: 0.7874\n",
      "Final Train F1 Score: 0.6937\n",
      "Final Test Accuracy: 0.7874\n",
      "Final Test F1 Score: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadhil\\AppData\\Local\\Temp\\ipykernel_10420\\1212388360.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_results = pd.concat([result, eval_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "result = train_and_evaluate_model(NODE_model, \"NODE Classifier\", X_train_t, X_test_t, y_train_t, y_test_t)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tab-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion, embed_size)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is expected to have shape [batch_size, sequence_length, embed_size]\n",
    "        attention = self.attention(x, x, x)[0]\n",
    "        x = self.dropout(self.norm1(attention + x))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "class TabularTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, embed_size, num_heads, forward_expansion, dropout):\n",
    "        super(TabularTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_size)\n",
    "        self.transformer_block = TransformerBlock(\n",
    "            embed_size=embed_size,\n",
    "            heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            forward_expansion=forward_expansion\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add sequence dimension\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = x.squeeze(1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define Tab-Transfomer Model\n",
    "TabTR_model = TabularTransformer(\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    embed_size=32,\n",
    "    num_heads=4,\n",
    "    forward_expansion=128,\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fadhil\\AppData\\Local\\Temp\\ipykernel_10420\\3282095067.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
      "C:\\Users\\fadhil\\AppData\\Local\\Temp\\ipykernel_10420\\3282095067.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "result = train_and_evaluate_model(TabTR_model, \"Tab-Transformer\", X_train_t, X_test_t, y_train_t, y_test_t)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fadhil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.55543 | val_0_accuracy: 0.78735 | val_0_auc: 0.52068 |  0:00:02s\n",
      "epoch 1  | loss: 0.51661 | val_0_accuracy: 0.78754 | val_0_auc: 0.561   |  0:00:05s\n",
      "epoch 2  | loss: 0.51512 | val_0_accuracy: 0.78735 | val_0_auc: 0.56659 |  0:00:08s\n",
      "epoch 3  | loss: 0.51601 | val_0_accuracy: 0.78735 | val_0_auc: 0.56472 |  0:00:11s\n",
      "epoch 4  | loss: 0.5135  | val_0_accuracy: 0.78735 | val_0_auc: 0.57902 |  0:00:13s\n",
      "epoch 5  | loss: 0.51189 | val_0_accuracy: 0.78735 | val_0_auc: 0.57787 |  0:00:16s\n",
      "epoch 6  | loss: 0.51256 | val_0_accuracy: 0.78735 | val_0_auc: 0.57577 |  0:00:19s\n",
      "epoch 7  | loss: 0.51156 | val_0_accuracy: 0.78735 | val_0_auc: 0.58253 |  0:00:22s\n",
      "epoch 8  | loss: 0.51163 | val_0_accuracy: 0.78735 | val_0_auc: 0.57931 |  0:00:24s\n",
      "epoch 9  | loss: 0.51149 | val_0_accuracy: 0.78735 | val_0_auc: 0.57449 |  0:00:27s\n",
      "epoch 10 | loss: 0.51226 | val_0_accuracy: 0.78735 | val_0_auc: 0.572   |  0:00:30s\n",
      "epoch 11 | loss: 0.51173 | val_0_accuracy: 0.78735 | val_0_auc: 0.57378 |  0:00:33s\n",
      "epoch 12 | loss: 0.5122  | val_0_accuracy: 0.78735 | val_0_auc: 0.57138 |  0:00:36s\n",
      "epoch 13 | loss: 0.51167 | val_0_accuracy: 0.78735 | val_0_auc: 0.57763 |  0:00:39s\n",
      "epoch 14 | loss: 0.51237 | val_0_accuracy: 0.78735 | val_0_auc: 0.57768 |  0:00:42s\n",
      "epoch 15 | loss: 0.51161 | val_0_accuracy: 0.78735 | val_0_auc: 0.57403 |  0:00:44s\n",
      "epoch 16 | loss: 0.51178 | val_0_accuracy: 0.78735 | val_0_auc: 0.57572 |  0:00:47s\n",
      "epoch 17 | loss: 0.51119 | val_0_accuracy: 0.78735 | val_0_auc: 0.57779 |  0:00:50s\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.58253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fadhil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7874\n",
      "F1: 0.6937\n",
      "roc_auc: 0.5825\n"
     ]
    }
   ],
   "source": [
    "# Define TabNet Model\n",
    "TabNet_model = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                         optimizer_params=dict(lr=2e-2),\n",
    "                         scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                         scheduler_params=dict(step_size=10, gamma=0.9),\n",
    "                         mask_type='sparsemax')\n",
    "\n",
    "# Train TabNet_model\n",
    "TabNet_model.fit(X_train=X_train, \n",
    "          y_train=y_train, \n",
    "          eval_set=[(X_test, y_test)],\n",
    "          eval_metric=['accuracy', 'auc'],\n",
    "          max_epochs=100, \n",
    "          patience=10,\n",
    "          batch_size=256,\n",
    "          virtual_batch_size=128,\n",
    "          num_workers=0,\n",
    "          drop_last=False)\n",
    "\n",
    "result = train_eval_non_scratch(TabNet_model, \"Tabnet\", X_train, X_test, y_train, y_test)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7872\n",
      "F1: 0.6939\n",
      "roc_auc: 0.5415\n"
     ]
    }
   ],
   "source": [
    "# Define Random Forest Model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train & Eval with function\n",
    "result = train_eval_non_scratch(rf_model, \"Random Forest\", X_train, X_test, y_train, y_test)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7717\n",
      "F1: 0.7005\n",
      "roc_auc: 0.5366\n"
     ]
    }
   ],
   "source": [
    "# Define XGBoost Model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train & Eval with function\n",
    "result = train_eval_non_scratch(xgb_model, \"XGBoost\", X_train, X_test, y_train, y_test)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4519, number of negative: 16737\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4180\n",
      "[LightGBM] [Info] Number of data points in the train set: 21256, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.212599 -> initscore=-1.309331\n",
      "[LightGBM] [Info] Start training from score -1.309331\n",
      "Accuracy: 0.7862\n",
      "F1: 0.6945\n",
      "roc_auc: 0.5503\n"
     ]
    }
   ],
   "source": [
    "# Define LightGBM Model\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Train & Eval with function\n",
    "result = train_eval_non_scratch(lgbm_model, \"LightGBM\", X_train, X_test, y_train, y_test)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.037999\n",
      "0:\tlearn: 0.6783259\ttotal: 9.46ms\tremaining: 9.45s\n",
      "1:\tlearn: 0.6653569\ttotal: 17.8ms\tremaining: 8.89s\n",
      "2:\tlearn: 0.6534001\ttotal: 26.2ms\tremaining: 8.7s\n",
      "3:\tlearn: 0.6418791\ttotal: 33.8ms\tremaining: 8.41s\n",
      "4:\tlearn: 0.6317432\ttotal: 41.5ms\tremaining: 8.26s\n",
      "5:\tlearn: 0.6224813\ttotal: 48.5ms\tremaining: 8.04s\n",
      "6:\tlearn: 0.6133877\ttotal: 56ms\tremaining: 7.95s\n",
      "7:\tlearn: 0.6051032\ttotal: 64.3ms\tremaining: 7.98s\n",
      "8:\tlearn: 0.5974258\ttotal: 70.8ms\tremaining: 7.8s\n",
      "9:\tlearn: 0.5903609\ttotal: 78ms\tremaining: 7.72s\n",
      "10:\tlearn: 0.5838927\ttotal: 84.8ms\tremaining: 7.63s\n",
      "11:\tlearn: 0.5780067\ttotal: 92ms\tremaining: 7.57s\n",
      "12:\tlearn: 0.5726147\ttotal: 99.3ms\tremaining: 7.54s\n",
      "13:\tlearn: 0.5674656\ttotal: 106ms\tremaining: 7.48s\n",
      "14:\tlearn: 0.5627534\ttotal: 114ms\tremaining: 7.51s\n",
      "15:\tlearn: 0.5583541\ttotal: 121ms\tremaining: 7.46s\n",
      "16:\tlearn: 0.5544361\ttotal: 128ms\tremaining: 7.42s\n",
      "17:\tlearn: 0.5510371\ttotal: 136ms\tremaining: 7.44s\n",
      "18:\tlearn: 0.5476335\ttotal: 143ms\tremaining: 7.41s\n",
      "19:\tlearn: 0.5447489\ttotal: 150ms\tremaining: 7.37s\n",
      "20:\tlearn: 0.5419772\ttotal: 158ms\tremaining: 7.35s\n",
      "21:\tlearn: 0.5393379\ttotal: 164ms\tremaining: 7.3s\n",
      "22:\tlearn: 0.5368165\ttotal: 171ms\tremaining: 7.26s\n",
      "23:\tlearn: 0.5347339\ttotal: 177ms\tremaining: 7.2s\n",
      "24:\tlearn: 0.5327423\ttotal: 184ms\tremaining: 7.19s\n",
      "25:\tlearn: 0.5307757\ttotal: 192ms\tremaining: 7.18s\n",
      "26:\tlearn: 0.5289404\ttotal: 199ms\tremaining: 7.19s\n",
      "27:\tlearn: 0.5272251\ttotal: 206ms\tremaining: 7.17s\n",
      "28:\tlearn: 0.5256316\ttotal: 215ms\tremaining: 7.19s\n",
      "29:\tlearn: 0.5241975\ttotal: 223ms\tremaining: 7.2s\n",
      "30:\tlearn: 0.5228753\ttotal: 230ms\tremaining: 7.19s\n",
      "31:\tlearn: 0.5216078\ttotal: 237ms\tremaining: 7.17s\n",
      "32:\tlearn: 0.5204225\ttotal: 244ms\tremaining: 7.13s\n",
      "33:\tlearn: 0.5192092\ttotal: 250ms\tremaining: 7.1s\n",
      "34:\tlearn: 0.5181528\ttotal: 256ms\tremaining: 7.06s\n",
      "35:\tlearn: 0.5173428\ttotal: 263ms\tremaining: 7.05s\n",
      "36:\tlearn: 0.5164190\ttotal: 271ms\tremaining: 7.05s\n",
      "37:\tlearn: 0.5157128\ttotal: 277ms\tremaining: 7.02s\n",
      "38:\tlearn: 0.5149538\ttotal: 283ms\tremaining: 6.98s\n",
      "39:\tlearn: 0.5142201\ttotal: 290ms\tremaining: 6.96s\n",
      "40:\tlearn: 0.5134556\ttotal: 296ms\tremaining: 6.92s\n",
      "41:\tlearn: 0.5128267\ttotal: 302ms\tremaining: 6.89s\n",
      "42:\tlearn: 0.5122345\ttotal: 308ms\tremaining: 6.86s\n",
      "43:\tlearn: 0.5117489\ttotal: 315ms\tremaining: 6.84s\n",
      "44:\tlearn: 0.5112980\ttotal: 322ms\tremaining: 6.83s\n",
      "45:\tlearn: 0.5107218\ttotal: 328ms\tremaining: 6.81s\n",
      "46:\tlearn: 0.5102085\ttotal: 336ms\tremaining: 6.81s\n",
      "47:\tlearn: 0.5097995\ttotal: 342ms\tremaining: 6.79s\n",
      "48:\tlearn: 0.5093471\ttotal: 349ms\tremaining: 6.77s\n",
      "49:\tlearn: 0.5089661\ttotal: 355ms\tremaining: 6.75s\n",
      "50:\tlearn: 0.5085617\ttotal: 362ms\tremaining: 6.73s\n",
      "51:\tlearn: 0.5081260\ttotal: 368ms\tremaining: 6.72s\n",
      "52:\tlearn: 0.5077925\ttotal: 375ms\tremaining: 6.7s\n",
      "53:\tlearn: 0.5074617\ttotal: 382ms\tremaining: 6.68s\n",
      "54:\tlearn: 0.5071348\ttotal: 388ms\tremaining: 6.67s\n",
      "55:\tlearn: 0.5068318\ttotal: 394ms\tremaining: 6.65s\n",
      "56:\tlearn: 0.5064257\ttotal: 402ms\tremaining: 6.65s\n",
      "57:\tlearn: 0.5061131\ttotal: 410ms\tremaining: 6.65s\n",
      "58:\tlearn: 0.5058107\ttotal: 418ms\tremaining: 6.66s\n",
      "59:\tlearn: 0.5054690\ttotal: 426ms\tremaining: 6.68s\n",
      "60:\tlearn: 0.5051675\ttotal: 434ms\tremaining: 6.68s\n",
      "61:\tlearn: 0.5049276\ttotal: 441ms\tremaining: 6.67s\n",
      "62:\tlearn: 0.5046558\ttotal: 448ms\tremaining: 6.67s\n",
      "63:\tlearn: 0.5043852\ttotal: 455ms\tremaining: 6.65s\n",
      "64:\tlearn: 0.5041706\ttotal: 463ms\tremaining: 6.66s\n",
      "65:\tlearn: 0.5039115\ttotal: 470ms\tremaining: 6.65s\n",
      "66:\tlearn: 0.5037120\ttotal: 477ms\tremaining: 6.64s\n",
      "67:\tlearn: 0.5034498\ttotal: 483ms\tremaining: 6.63s\n",
      "68:\tlearn: 0.5032421\ttotal: 490ms\tremaining: 6.61s\n",
      "69:\tlearn: 0.5031963\ttotal: 493ms\tremaining: 6.55s\n",
      "70:\tlearn: 0.5029462\ttotal: 499ms\tremaining: 6.53s\n",
      "71:\tlearn: 0.5027188\ttotal: 506ms\tremaining: 6.52s\n",
      "72:\tlearn: 0.5024991\ttotal: 513ms\tremaining: 6.51s\n",
      "73:\tlearn: 0.5022665\ttotal: 521ms\tremaining: 6.52s\n",
      "74:\tlearn: 0.5020250\ttotal: 528ms\tremaining: 6.51s\n",
      "75:\tlearn: 0.5018251\ttotal: 535ms\tremaining: 6.51s\n",
      "76:\tlearn: 0.5016724\ttotal: 542ms\tremaining: 6.5s\n",
      "77:\tlearn: 0.5014891\ttotal: 549ms\tremaining: 6.49s\n",
      "78:\tlearn: 0.5013171\ttotal: 556ms\tremaining: 6.48s\n",
      "79:\tlearn: 0.5010955\ttotal: 563ms\tremaining: 6.48s\n",
      "80:\tlearn: 0.5009383\ttotal: 571ms\tremaining: 6.48s\n",
      "81:\tlearn: 0.5007327\ttotal: 577ms\tremaining: 6.46s\n",
      "82:\tlearn: 0.5005298\ttotal: 585ms\tremaining: 6.46s\n",
      "83:\tlearn: 0.5003525\ttotal: 591ms\tremaining: 6.44s\n",
      "84:\tlearn: 0.5002412\ttotal: 597ms\tremaining: 6.43s\n",
      "85:\tlearn: 0.5000602\ttotal: 604ms\tremaining: 6.42s\n",
      "86:\tlearn: 0.4999099\ttotal: 610ms\tremaining: 6.41s\n",
      "87:\tlearn: 0.4997504\ttotal: 621ms\tremaining: 6.43s\n",
      "88:\tlearn: 0.4995995\ttotal: 630ms\tremaining: 6.45s\n",
      "89:\tlearn: 0.4994866\ttotal: 637ms\tremaining: 6.44s\n",
      "90:\tlearn: 0.4993107\ttotal: 645ms\tremaining: 6.45s\n",
      "91:\tlearn: 0.4991582\ttotal: 652ms\tremaining: 6.43s\n",
      "92:\tlearn: 0.4989985\ttotal: 659ms\tremaining: 6.42s\n",
      "93:\tlearn: 0.4988546\ttotal: 664ms\tremaining: 6.4s\n",
      "94:\tlearn: 0.4986212\ttotal: 671ms\tremaining: 6.39s\n",
      "95:\tlearn: 0.4984968\ttotal: 677ms\tremaining: 6.38s\n",
      "96:\tlearn: 0.4983242\ttotal: 684ms\tremaining: 6.36s\n",
      "97:\tlearn: 0.4981760\ttotal: 690ms\tremaining: 6.35s\n",
      "98:\tlearn: 0.4980394\ttotal: 696ms\tremaining: 6.34s\n",
      "99:\tlearn: 0.4978615\ttotal: 703ms\tremaining: 6.32s\n",
      "100:\tlearn: 0.4977815\ttotal: 709ms\tremaining: 6.31s\n",
      "101:\tlearn: 0.4976536\ttotal: 715ms\tremaining: 6.3s\n",
      "102:\tlearn: 0.4975378\ttotal: 723ms\tremaining: 6.29s\n",
      "103:\tlearn: 0.4974435\ttotal: 729ms\tremaining: 6.28s\n",
      "104:\tlearn: 0.4973251\ttotal: 737ms\tremaining: 6.28s\n",
      "105:\tlearn: 0.4972231\ttotal: 743ms\tremaining: 6.27s\n",
      "106:\tlearn: 0.4971105\ttotal: 750ms\tremaining: 6.26s\n",
      "107:\tlearn: 0.4969841\ttotal: 756ms\tremaining: 6.25s\n",
      "108:\tlearn: 0.4968054\ttotal: 763ms\tremaining: 6.24s\n",
      "109:\tlearn: 0.4967276\ttotal: 770ms\tremaining: 6.23s\n",
      "110:\tlearn: 0.4965530\ttotal: 776ms\tremaining: 6.21s\n",
      "111:\tlearn: 0.4964122\ttotal: 784ms\tremaining: 6.21s\n",
      "112:\tlearn: 0.4963087\ttotal: 790ms\tremaining: 6.2s\n",
      "113:\tlearn: 0.4961704\ttotal: 798ms\tremaining: 6.2s\n",
      "114:\tlearn: 0.4960410\ttotal: 804ms\tremaining: 6.19s\n",
      "115:\tlearn: 0.4958733\ttotal: 810ms\tremaining: 6.17s\n",
      "116:\tlearn: 0.4957650\ttotal: 819ms\tremaining: 6.18s\n",
      "117:\tlearn: 0.4956417\ttotal: 827ms\tremaining: 6.18s\n",
      "118:\tlearn: 0.4954847\ttotal: 834ms\tremaining: 6.17s\n",
      "119:\tlearn: 0.4953527\ttotal: 841ms\tremaining: 6.17s\n",
      "120:\tlearn: 0.4952608\ttotal: 848ms\tremaining: 6.16s\n",
      "121:\tlearn: 0.4951267\ttotal: 854ms\tremaining: 6.15s\n",
      "122:\tlearn: 0.4950558\ttotal: 860ms\tremaining: 6.13s\n",
      "123:\tlearn: 0.4949190\ttotal: 867ms\tremaining: 6.12s\n",
      "124:\tlearn: 0.4948633\ttotal: 872ms\tremaining: 6.11s\n",
      "125:\tlearn: 0.4947681\ttotal: 878ms\tremaining: 6.09s\n",
      "126:\tlearn: 0.4946920\ttotal: 885ms\tremaining: 6.08s\n",
      "127:\tlearn: 0.4945436\ttotal: 892ms\tremaining: 6.07s\n",
      "128:\tlearn: 0.4943753\ttotal: 898ms\tremaining: 6.06s\n",
      "129:\tlearn: 0.4942268\ttotal: 905ms\tremaining: 6.05s\n",
      "130:\tlearn: 0.4941276\ttotal: 911ms\tremaining: 6.04s\n",
      "131:\tlearn: 0.4940034\ttotal: 918ms\tremaining: 6.03s\n",
      "132:\tlearn: 0.4939116\ttotal: 925ms\tremaining: 6.03s\n",
      "133:\tlearn: 0.4938108\ttotal: 932ms\tremaining: 6.02s\n",
      "134:\tlearn: 0.4936480\ttotal: 939ms\tremaining: 6.01s\n",
      "135:\tlearn: 0.4935105\ttotal: 945ms\tremaining: 6s\n",
      "136:\tlearn: 0.4933878\ttotal: 952ms\tremaining: 6s\n",
      "137:\tlearn: 0.4932818\ttotal: 959ms\tremaining: 5.99s\n",
      "138:\tlearn: 0.4931516\ttotal: 966ms\tremaining: 5.99s\n",
      "139:\tlearn: 0.4930674\ttotal: 974ms\tremaining: 5.98s\n",
      "140:\tlearn: 0.4929467\ttotal: 981ms\tremaining: 5.98s\n",
      "141:\tlearn: 0.4928541\ttotal: 988ms\tremaining: 5.97s\n",
      "142:\tlearn: 0.4927338\ttotal: 995ms\tremaining: 5.96s\n",
      "143:\tlearn: 0.4926524\ttotal: 1s\tremaining: 5.95s\n",
      "144:\tlearn: 0.4925991\ttotal: 1.01s\tremaining: 5.94s\n",
      "145:\tlearn: 0.4924214\ttotal: 1.02s\tremaining: 5.95s\n",
      "146:\tlearn: 0.4923297\ttotal: 1.02s\tremaining: 5.95s\n",
      "147:\tlearn: 0.4922038\ttotal: 1.03s\tremaining: 5.95s\n",
      "148:\tlearn: 0.4920540\ttotal: 1.04s\tremaining: 5.94s\n",
      "149:\tlearn: 0.4919029\ttotal: 1.05s\tremaining: 5.94s\n",
      "150:\tlearn: 0.4917914\ttotal: 1.05s\tremaining: 5.93s\n",
      "151:\tlearn: 0.4916662\ttotal: 1.06s\tremaining: 5.92s\n",
      "152:\tlearn: 0.4915409\ttotal: 1.07s\tremaining: 5.91s\n",
      "153:\tlearn: 0.4913823\ttotal: 1.07s\tremaining: 5.9s\n",
      "154:\tlearn: 0.4912576\ttotal: 1.08s\tremaining: 5.89s\n",
      "155:\tlearn: 0.4911527\ttotal: 1.09s\tremaining: 5.88s\n",
      "156:\tlearn: 0.4909950\ttotal: 1.09s\tremaining: 5.87s\n",
      "157:\tlearn: 0.4909056\ttotal: 1.1s\tremaining: 5.87s\n",
      "158:\tlearn: 0.4907477\ttotal: 1.11s\tremaining: 5.86s\n",
      "159:\tlearn: 0.4906382\ttotal: 1.11s\tremaining: 5.85s\n",
      "160:\tlearn: 0.4904854\ttotal: 1.12s\tremaining: 5.84s\n",
      "161:\tlearn: 0.4903393\ttotal: 1.13s\tremaining: 5.84s\n",
      "162:\tlearn: 0.4902251\ttotal: 1.14s\tremaining: 5.83s\n",
      "163:\tlearn: 0.4901319\ttotal: 1.14s\tremaining: 5.82s\n",
      "164:\tlearn: 0.4900046\ttotal: 1.15s\tremaining: 5.81s\n",
      "165:\tlearn: 0.4898861\ttotal: 1.16s\tremaining: 5.8s\n",
      "166:\tlearn: 0.4897779\ttotal: 1.16s\tremaining: 5.79s\n",
      "167:\tlearn: 0.4896584\ttotal: 1.17s\tremaining: 5.78s\n",
      "168:\tlearn: 0.4894841\ttotal: 1.18s\tremaining: 5.78s\n",
      "169:\tlearn: 0.4893345\ttotal: 1.18s\tremaining: 5.77s\n",
      "170:\tlearn: 0.4892203\ttotal: 1.19s\tremaining: 5.77s\n",
      "171:\tlearn: 0.4890989\ttotal: 1.2s\tremaining: 5.76s\n",
      "172:\tlearn: 0.4889663\ttotal: 1.2s\tremaining: 5.75s\n",
      "173:\tlearn: 0.4888770\ttotal: 1.21s\tremaining: 5.74s\n",
      "174:\tlearn: 0.4887281\ttotal: 1.22s\tremaining: 5.73s\n",
      "175:\tlearn: 0.4885896\ttotal: 1.22s\tremaining: 5.72s\n",
      "176:\tlearn: 0.4884777\ttotal: 1.23s\tremaining: 5.71s\n",
      "177:\tlearn: 0.4883656\ttotal: 1.24s\tremaining: 5.71s\n",
      "178:\tlearn: 0.4882472\ttotal: 1.24s\tremaining: 5.71s\n",
      "179:\tlearn: 0.4881009\ttotal: 1.25s\tremaining: 5.7s\n",
      "180:\tlearn: 0.4879568\ttotal: 1.26s\tremaining: 5.69s\n",
      "181:\tlearn: 0.4877902\ttotal: 1.26s\tremaining: 5.68s\n",
      "182:\tlearn: 0.4877059\ttotal: 1.27s\tremaining: 5.67s\n",
      "183:\tlearn: 0.4876299\ttotal: 1.28s\tremaining: 5.67s\n",
      "184:\tlearn: 0.4875280\ttotal: 1.28s\tremaining: 5.66s\n",
      "185:\tlearn: 0.4873878\ttotal: 1.29s\tremaining: 5.65s\n",
      "186:\tlearn: 0.4872685\ttotal: 1.3s\tremaining: 5.64s\n",
      "187:\tlearn: 0.4871990\ttotal: 1.3s\tremaining: 5.63s\n",
      "188:\tlearn: 0.4870953\ttotal: 1.31s\tremaining: 5.63s\n",
      "189:\tlearn: 0.4869816\ttotal: 1.32s\tremaining: 5.62s\n",
      "190:\tlearn: 0.4868709\ttotal: 1.32s\tremaining: 5.61s\n",
      "191:\tlearn: 0.4867633\ttotal: 1.33s\tremaining: 5.6s\n",
      "192:\tlearn: 0.4866299\ttotal: 1.34s\tremaining: 5.59s\n",
      "193:\tlearn: 0.4864931\ttotal: 1.34s\tremaining: 5.58s\n",
      "194:\tlearn: 0.4863835\ttotal: 1.35s\tremaining: 5.58s\n",
      "195:\tlearn: 0.4862187\ttotal: 1.36s\tremaining: 5.57s\n",
      "196:\tlearn: 0.4860428\ttotal: 1.36s\tremaining: 5.55s\n",
      "197:\tlearn: 0.4859573\ttotal: 1.37s\tremaining: 5.54s\n",
      "198:\tlearn: 0.4858425\ttotal: 1.38s\tremaining: 5.53s\n",
      "199:\tlearn: 0.4857397\ttotal: 1.38s\tremaining: 5.53s\n",
      "200:\tlearn: 0.4856112\ttotal: 1.39s\tremaining: 5.51s\n",
      "201:\tlearn: 0.4855637\ttotal: 1.39s\tremaining: 5.5s\n",
      "202:\tlearn: 0.4854794\ttotal: 1.4s\tremaining: 5.5s\n",
      "203:\tlearn: 0.4853097\ttotal: 1.41s\tremaining: 5.49s\n",
      "204:\tlearn: 0.4851770\ttotal: 1.41s\tremaining: 5.48s\n",
      "205:\tlearn: 0.4850651\ttotal: 1.42s\tremaining: 5.47s\n",
      "206:\tlearn: 0.4849559\ttotal: 1.43s\tremaining: 5.46s\n",
      "207:\tlearn: 0.4847956\ttotal: 1.43s\tremaining: 5.46s\n",
      "208:\tlearn: 0.4847178\ttotal: 1.44s\tremaining: 5.46s\n",
      "209:\tlearn: 0.4845960\ttotal: 1.45s\tremaining: 5.46s\n",
      "210:\tlearn: 0.4844983\ttotal: 1.46s\tremaining: 5.45s\n",
      "211:\tlearn: 0.4843576\ttotal: 1.46s\tremaining: 5.44s\n",
      "212:\tlearn: 0.4842315\ttotal: 1.47s\tremaining: 5.43s\n",
      "213:\tlearn: 0.4841173\ttotal: 1.48s\tremaining: 5.42s\n",
      "214:\tlearn: 0.4839874\ttotal: 1.48s\tremaining: 5.41s\n",
      "215:\tlearn: 0.4838678\ttotal: 1.49s\tremaining: 5.4s\n",
      "216:\tlearn: 0.4837433\ttotal: 1.49s\tremaining: 5.39s\n",
      "217:\tlearn: 0.4836260\ttotal: 1.5s\tremaining: 5.38s\n",
      "218:\tlearn: 0.4834882\ttotal: 1.51s\tremaining: 5.38s\n",
      "219:\tlearn: 0.4832921\ttotal: 1.51s\tremaining: 5.37s\n",
      "220:\tlearn: 0.4831689\ttotal: 1.52s\tremaining: 5.37s\n",
      "221:\tlearn: 0.4830342\ttotal: 1.53s\tremaining: 5.36s\n",
      "222:\tlearn: 0.4829077\ttotal: 1.54s\tremaining: 5.35s\n",
      "223:\tlearn: 0.4828162\ttotal: 1.54s\tremaining: 5.34s\n",
      "224:\tlearn: 0.4827214\ttotal: 1.55s\tremaining: 5.34s\n",
      "225:\tlearn: 0.4826184\ttotal: 1.55s\tremaining: 5.33s\n",
      "226:\tlearn: 0.4824823\ttotal: 1.56s\tremaining: 5.32s\n",
      "227:\tlearn: 0.4823482\ttotal: 1.57s\tremaining: 5.31s\n",
      "228:\tlearn: 0.4822103\ttotal: 1.57s\tremaining: 5.3s\n",
      "229:\tlearn: 0.4821108\ttotal: 1.58s\tremaining: 5.3s\n",
      "230:\tlearn: 0.4820037\ttotal: 1.59s\tremaining: 5.29s\n",
      "231:\tlearn: 0.4818689\ttotal: 1.59s\tremaining: 5.28s\n",
      "232:\tlearn: 0.4818001\ttotal: 1.6s\tremaining: 5.27s\n",
      "233:\tlearn: 0.4816471\ttotal: 1.61s\tremaining: 5.26s\n",
      "234:\tlearn: 0.4815163\ttotal: 1.61s\tremaining: 5.26s\n",
      "235:\tlearn: 0.4813871\ttotal: 1.62s\tremaining: 5.25s\n",
      "236:\tlearn: 0.4812949\ttotal: 1.63s\tremaining: 5.24s\n",
      "237:\tlearn: 0.4811307\ttotal: 1.64s\tremaining: 5.24s\n",
      "238:\tlearn: 0.4810401\ttotal: 1.64s\tremaining: 5.23s\n",
      "239:\tlearn: 0.4808928\ttotal: 1.65s\tremaining: 5.22s\n",
      "240:\tlearn: 0.4807960\ttotal: 1.66s\tremaining: 5.21s\n",
      "241:\tlearn: 0.4807526\ttotal: 1.66s\tremaining: 5.21s\n",
      "242:\tlearn: 0.4806314\ttotal: 1.67s\tremaining: 5.2s\n",
      "243:\tlearn: 0.4805095\ttotal: 1.68s\tremaining: 5.2s\n",
      "244:\tlearn: 0.4804492\ttotal: 1.68s\tremaining: 5.19s\n",
      "245:\tlearn: 0.4803231\ttotal: 1.69s\tremaining: 5.18s\n",
      "246:\tlearn: 0.4802108\ttotal: 1.7s\tremaining: 5.17s\n",
      "247:\tlearn: 0.4800713\ttotal: 1.7s\tremaining: 5.17s\n",
      "248:\tlearn: 0.4798877\ttotal: 1.71s\tremaining: 5.16s\n",
      "249:\tlearn: 0.4797560\ttotal: 1.72s\tremaining: 5.15s\n",
      "250:\tlearn: 0.4796464\ttotal: 1.72s\tremaining: 5.14s\n",
      "251:\tlearn: 0.4795116\ttotal: 1.73s\tremaining: 5.13s\n",
      "252:\tlearn: 0.4794226\ttotal: 1.74s\tremaining: 5.13s\n",
      "253:\tlearn: 0.4793264\ttotal: 1.74s\tremaining: 5.12s\n",
      "254:\tlearn: 0.4792089\ttotal: 1.75s\tremaining: 5.12s\n",
      "255:\tlearn: 0.4790656\ttotal: 1.76s\tremaining: 5.11s\n",
      "256:\tlearn: 0.4788884\ttotal: 1.76s\tremaining: 5.1s\n",
      "257:\tlearn: 0.4787398\ttotal: 1.77s\tremaining: 5.09s\n",
      "258:\tlearn: 0.4786030\ttotal: 1.78s\tremaining: 5.08s\n",
      "259:\tlearn: 0.4785109\ttotal: 1.78s\tremaining: 5.08s\n",
      "260:\tlearn: 0.4783896\ttotal: 1.79s\tremaining: 5.07s\n",
      "261:\tlearn: 0.4782652\ttotal: 1.8s\tremaining: 5.06s\n",
      "262:\tlearn: 0.4781356\ttotal: 1.8s\tremaining: 5.05s\n",
      "263:\tlearn: 0.4780145\ttotal: 1.81s\tremaining: 5.05s\n",
      "264:\tlearn: 0.4779026\ttotal: 1.82s\tremaining: 5.04s\n",
      "265:\tlearn: 0.4777790\ttotal: 1.82s\tremaining: 5.03s\n",
      "266:\tlearn: 0.4777149\ttotal: 1.83s\tremaining: 5.02s\n",
      "267:\tlearn: 0.4775846\ttotal: 1.84s\tremaining: 5.02s\n",
      "268:\tlearn: 0.4774349\ttotal: 1.84s\tremaining: 5.01s\n",
      "269:\tlearn: 0.4773031\ttotal: 1.85s\tremaining: 5s\n",
      "270:\tlearn: 0.4771936\ttotal: 1.86s\tremaining: 4.99s\n",
      "271:\tlearn: 0.4770554\ttotal: 1.86s\tremaining: 4.99s\n",
      "272:\tlearn: 0.4769693\ttotal: 1.87s\tremaining: 4.98s\n",
      "273:\tlearn: 0.4768344\ttotal: 1.88s\tremaining: 4.97s\n",
      "274:\tlearn: 0.4767062\ttotal: 1.88s\tremaining: 4.96s\n",
      "275:\tlearn: 0.4765754\ttotal: 1.89s\tremaining: 4.95s\n",
      "276:\tlearn: 0.4764319\ttotal: 1.89s\tremaining: 4.95s\n",
      "277:\tlearn: 0.4763157\ttotal: 1.9s\tremaining: 4.94s\n",
      "278:\tlearn: 0.4761851\ttotal: 1.91s\tremaining: 4.93s\n",
      "279:\tlearn: 0.4760701\ttotal: 1.91s\tremaining: 4.92s\n",
      "280:\tlearn: 0.4760018\ttotal: 1.92s\tremaining: 4.91s\n",
      "281:\tlearn: 0.4758884\ttotal: 1.93s\tremaining: 4.91s\n",
      "282:\tlearn: 0.4757373\ttotal: 1.93s\tremaining: 4.9s\n",
      "283:\tlearn: 0.4755856\ttotal: 1.94s\tremaining: 4.89s\n",
      "284:\tlearn: 0.4754633\ttotal: 1.95s\tremaining: 4.88s\n",
      "285:\tlearn: 0.4753353\ttotal: 1.95s\tremaining: 4.88s\n",
      "286:\tlearn: 0.4752168\ttotal: 1.96s\tremaining: 4.87s\n",
      "287:\tlearn: 0.4750603\ttotal: 1.97s\tremaining: 4.86s\n",
      "288:\tlearn: 0.4749197\ttotal: 1.97s\tremaining: 4.86s\n",
      "289:\tlearn: 0.4747837\ttotal: 1.98s\tremaining: 4.85s\n",
      "290:\tlearn: 0.4746515\ttotal: 1.99s\tremaining: 4.84s\n",
      "291:\tlearn: 0.4745850\ttotal: 1.99s\tremaining: 4.83s\n",
      "292:\tlearn: 0.4744608\ttotal: 2s\tremaining: 4.82s\n",
      "293:\tlearn: 0.4743199\ttotal: 2s\tremaining: 4.82s\n",
      "294:\tlearn: 0.4742123\ttotal: 2.01s\tremaining: 4.81s\n",
      "295:\tlearn: 0.4740458\ttotal: 2.02s\tremaining: 4.8s\n",
      "296:\tlearn: 0.4739272\ttotal: 2.02s\tremaining: 4.79s\n",
      "297:\tlearn: 0.4737922\ttotal: 2.03s\tremaining: 4.78s\n",
      "298:\tlearn: 0.4736631\ttotal: 2.04s\tremaining: 4.78s\n",
      "299:\tlearn: 0.4735270\ttotal: 2.04s\tremaining: 4.77s\n",
      "300:\tlearn: 0.4734033\ttotal: 2.05s\tremaining: 4.76s\n",
      "301:\tlearn: 0.4732379\ttotal: 2.06s\tremaining: 4.76s\n",
      "302:\tlearn: 0.4730961\ttotal: 2.06s\tremaining: 4.75s\n",
      "303:\tlearn: 0.4729674\ttotal: 2.07s\tremaining: 4.74s\n",
      "304:\tlearn: 0.4728212\ttotal: 2.08s\tremaining: 4.74s\n",
      "305:\tlearn: 0.4727352\ttotal: 2.08s\tremaining: 4.73s\n",
      "306:\tlearn: 0.4726293\ttotal: 2.09s\tremaining: 4.72s\n",
      "307:\tlearn: 0.4725017\ttotal: 2.1s\tremaining: 4.71s\n",
      "308:\tlearn: 0.4723052\ttotal: 2.1s\tremaining: 4.7s\n",
      "309:\tlearn: 0.4721608\ttotal: 2.11s\tremaining: 4.7s\n",
      "310:\tlearn: 0.4720331\ttotal: 2.12s\tremaining: 4.69s\n",
      "311:\tlearn: 0.4720039\ttotal: 2.12s\tremaining: 4.68s\n",
      "312:\tlearn: 0.4718849\ttotal: 2.13s\tremaining: 4.67s\n",
      "313:\tlearn: 0.4717632\ttotal: 2.13s\tremaining: 4.67s\n",
      "314:\tlearn: 0.4716339\ttotal: 2.14s\tremaining: 4.66s\n",
      "315:\tlearn: 0.4715118\ttotal: 2.15s\tremaining: 4.65s\n",
      "316:\tlearn: 0.4713784\ttotal: 2.15s\tremaining: 4.64s\n",
      "317:\tlearn: 0.4712311\ttotal: 2.16s\tremaining: 4.63s\n",
      "318:\tlearn: 0.4710603\ttotal: 2.17s\tremaining: 4.63s\n",
      "319:\tlearn: 0.4709659\ttotal: 2.17s\tremaining: 4.62s\n",
      "320:\tlearn: 0.4708404\ttotal: 2.18s\tremaining: 4.61s\n",
      "321:\tlearn: 0.4706855\ttotal: 2.19s\tremaining: 4.6s\n",
      "322:\tlearn: 0.4705171\ttotal: 2.19s\tremaining: 4.59s\n",
      "323:\tlearn: 0.4703633\ttotal: 2.2s\tremaining: 4.59s\n",
      "324:\tlearn: 0.4702582\ttotal: 2.21s\tremaining: 4.58s\n",
      "325:\tlearn: 0.4701352\ttotal: 2.21s\tremaining: 4.57s\n",
      "326:\tlearn: 0.4700270\ttotal: 2.22s\tremaining: 4.57s\n",
      "327:\tlearn: 0.4698727\ttotal: 2.22s\tremaining: 4.56s\n",
      "328:\tlearn: 0.4697803\ttotal: 2.23s\tremaining: 4.55s\n",
      "329:\tlearn: 0.4697012\ttotal: 2.24s\tremaining: 4.54s\n",
      "330:\tlearn: 0.4695667\ttotal: 2.24s\tremaining: 4.53s\n",
      "331:\tlearn: 0.4694653\ttotal: 2.25s\tremaining: 4.53s\n",
      "332:\tlearn: 0.4694211\ttotal: 2.25s\tremaining: 4.52s\n",
      "333:\tlearn: 0.4692627\ttotal: 2.26s\tremaining: 4.51s\n",
      "334:\tlearn: 0.4691111\ttotal: 2.27s\tremaining: 4.5s\n",
      "335:\tlearn: 0.4689956\ttotal: 2.27s\tremaining: 4.5s\n",
      "336:\tlearn: 0.4689009\ttotal: 2.28s\tremaining: 4.49s\n",
      "337:\tlearn: 0.4687729\ttotal: 2.29s\tremaining: 4.48s\n",
      "338:\tlearn: 0.4686366\ttotal: 2.29s\tremaining: 4.47s\n",
      "339:\tlearn: 0.4685009\ttotal: 2.3s\tremaining: 4.47s\n",
      "340:\tlearn: 0.4683467\ttotal: 2.31s\tremaining: 4.46s\n",
      "341:\tlearn: 0.4682086\ttotal: 2.31s\tremaining: 4.45s\n",
      "342:\tlearn: 0.4680919\ttotal: 2.32s\tremaining: 4.45s\n",
      "343:\tlearn: 0.4679517\ttotal: 2.33s\tremaining: 4.44s\n",
      "344:\tlearn: 0.4677822\ttotal: 2.33s\tremaining: 4.43s\n",
      "345:\tlearn: 0.4676491\ttotal: 2.34s\tremaining: 4.42s\n",
      "346:\tlearn: 0.4674530\ttotal: 2.35s\tremaining: 4.42s\n",
      "347:\tlearn: 0.4672521\ttotal: 2.35s\tremaining: 4.41s\n",
      "348:\tlearn: 0.4670674\ttotal: 2.36s\tremaining: 4.4s\n",
      "349:\tlearn: 0.4670221\ttotal: 2.37s\tremaining: 4.39s\n",
      "350:\tlearn: 0.4668747\ttotal: 2.37s\tremaining: 4.38s\n",
      "351:\tlearn: 0.4667194\ttotal: 2.38s\tremaining: 4.38s\n",
      "352:\tlearn: 0.4665981\ttotal: 2.38s\tremaining: 4.37s\n",
      "353:\tlearn: 0.4664399\ttotal: 2.39s\tremaining: 4.36s\n",
      "354:\tlearn: 0.4663161\ttotal: 2.4s\tremaining: 4.35s\n",
      "355:\tlearn: 0.4661776\ttotal: 2.4s\tremaining: 4.34s\n",
      "356:\tlearn: 0.4660309\ttotal: 2.41s\tremaining: 4.34s\n",
      "357:\tlearn: 0.4659280\ttotal: 2.41s\tremaining: 4.33s\n",
      "358:\tlearn: 0.4657659\ttotal: 2.42s\tremaining: 4.32s\n",
      "359:\tlearn: 0.4656286\ttotal: 2.43s\tremaining: 4.32s\n",
      "360:\tlearn: 0.4654604\ttotal: 2.43s\tremaining: 4.31s\n",
      "361:\tlearn: 0.4653347\ttotal: 2.44s\tremaining: 4.3s\n",
      "362:\tlearn: 0.4652309\ttotal: 2.45s\tremaining: 4.29s\n",
      "363:\tlearn: 0.4650556\ttotal: 2.45s\tremaining: 4.29s\n",
      "364:\tlearn: 0.4649540\ttotal: 2.46s\tremaining: 4.28s\n",
      "365:\tlearn: 0.4648613\ttotal: 2.48s\tremaining: 4.29s\n",
      "366:\tlearn: 0.4648335\ttotal: 2.48s\tremaining: 4.28s\n",
      "367:\tlearn: 0.4646471\ttotal: 2.49s\tremaining: 4.28s\n",
      "368:\tlearn: 0.4645062\ttotal: 2.5s\tremaining: 4.27s\n",
      "369:\tlearn: 0.4643539\ttotal: 2.5s\tremaining: 4.26s\n",
      "370:\tlearn: 0.4642297\ttotal: 2.51s\tremaining: 4.26s\n",
      "371:\tlearn: 0.4640606\ttotal: 2.52s\tremaining: 4.25s\n",
      "372:\tlearn: 0.4638831\ttotal: 2.52s\tremaining: 4.24s\n",
      "373:\tlearn: 0.4638517\ttotal: 2.53s\tremaining: 4.23s\n",
      "374:\tlearn: 0.4637068\ttotal: 2.54s\tremaining: 4.23s\n",
      "375:\tlearn: 0.4635331\ttotal: 2.54s\tremaining: 4.22s\n",
      "376:\tlearn: 0.4633788\ttotal: 2.55s\tremaining: 4.21s\n",
      "377:\tlearn: 0.4632498\ttotal: 2.55s\tremaining: 4.2s\n",
      "378:\tlearn: 0.4630686\ttotal: 2.56s\tremaining: 4.2s\n",
      "379:\tlearn: 0.4629706\ttotal: 2.57s\tremaining: 4.19s\n",
      "380:\tlearn: 0.4627798\ttotal: 2.57s\tremaining: 4.18s\n",
      "381:\tlearn: 0.4626501\ttotal: 2.58s\tremaining: 4.17s\n",
      "382:\tlearn: 0.4625142\ttotal: 2.59s\tremaining: 4.17s\n",
      "383:\tlearn: 0.4623672\ttotal: 2.59s\tremaining: 4.16s\n",
      "384:\tlearn: 0.4622094\ttotal: 2.6s\tremaining: 4.15s\n",
      "385:\tlearn: 0.4620737\ttotal: 2.61s\tremaining: 4.14s\n",
      "386:\tlearn: 0.4619788\ttotal: 2.61s\tremaining: 4.14s\n",
      "387:\tlearn: 0.4618448\ttotal: 2.62s\tremaining: 4.13s\n",
      "388:\tlearn: 0.4616797\ttotal: 2.63s\tremaining: 4.12s\n",
      "389:\tlearn: 0.4614986\ttotal: 2.63s\tremaining: 4.12s\n",
      "390:\tlearn: 0.4613072\ttotal: 2.64s\tremaining: 4.11s\n",
      "391:\tlearn: 0.4611035\ttotal: 2.65s\tremaining: 4.1s\n",
      "392:\tlearn: 0.4609890\ttotal: 2.65s\tremaining: 4.1s\n",
      "393:\tlearn: 0.4608381\ttotal: 2.66s\tremaining: 4.09s\n",
      "394:\tlearn: 0.4606793\ttotal: 2.67s\tremaining: 4.08s\n",
      "395:\tlearn: 0.4605045\ttotal: 2.67s\tremaining: 4.08s\n",
      "396:\tlearn: 0.4604085\ttotal: 2.68s\tremaining: 4.07s\n",
      "397:\tlearn: 0.4602762\ttotal: 2.69s\tremaining: 4.06s\n",
      "398:\tlearn: 0.4601396\ttotal: 2.69s\tremaining: 4.06s\n",
      "399:\tlearn: 0.4600056\ttotal: 2.7s\tremaining: 4.05s\n",
      "400:\tlearn: 0.4598030\ttotal: 2.71s\tremaining: 4.04s\n",
      "401:\tlearn: 0.4597011\ttotal: 2.71s\tremaining: 4.04s\n",
      "402:\tlearn: 0.4595569\ttotal: 2.72s\tremaining: 4.03s\n",
      "403:\tlearn: 0.4594508\ttotal: 2.73s\tremaining: 4.02s\n",
      "404:\tlearn: 0.4593298\ttotal: 2.73s\tremaining: 4.01s\n",
      "405:\tlearn: 0.4591756\ttotal: 2.74s\tremaining: 4.01s\n",
      "406:\tlearn: 0.4590565\ttotal: 2.75s\tremaining: 4s\n",
      "407:\tlearn: 0.4589114\ttotal: 2.75s\tremaining: 3.99s\n",
      "408:\tlearn: 0.4588061\ttotal: 2.76s\tremaining: 3.98s\n",
      "409:\tlearn: 0.4586491\ttotal: 2.76s\tremaining: 3.98s\n",
      "410:\tlearn: 0.4585295\ttotal: 2.77s\tremaining: 3.97s\n",
      "411:\tlearn: 0.4583366\ttotal: 2.78s\tremaining: 3.96s\n",
      "412:\tlearn: 0.4582343\ttotal: 2.78s\tremaining: 3.96s\n",
      "413:\tlearn: 0.4580580\ttotal: 2.79s\tremaining: 3.95s\n",
      "414:\tlearn: 0.4578785\ttotal: 2.8s\tremaining: 3.94s\n",
      "415:\tlearn: 0.4577192\ttotal: 2.8s\tremaining: 3.94s\n",
      "416:\tlearn: 0.4576172\ttotal: 2.81s\tremaining: 3.93s\n",
      "417:\tlearn: 0.4575168\ttotal: 2.82s\tremaining: 3.92s\n",
      "418:\tlearn: 0.4573889\ttotal: 2.82s\tremaining: 3.91s\n",
      "419:\tlearn: 0.4573073\ttotal: 2.83s\tremaining: 3.91s\n",
      "420:\tlearn: 0.4572267\ttotal: 2.84s\tremaining: 3.9s\n",
      "421:\tlearn: 0.4571380\ttotal: 2.84s\tremaining: 3.89s\n",
      "422:\tlearn: 0.4570044\ttotal: 2.85s\tremaining: 3.89s\n",
      "423:\tlearn: 0.4568510\ttotal: 2.86s\tremaining: 3.88s\n",
      "424:\tlearn: 0.4567178\ttotal: 2.86s\tremaining: 3.87s\n",
      "425:\tlearn: 0.4566045\ttotal: 2.87s\tremaining: 3.87s\n",
      "426:\tlearn: 0.4564971\ttotal: 2.88s\tremaining: 3.86s\n",
      "427:\tlearn: 0.4563119\ttotal: 2.88s\tremaining: 3.85s\n",
      "428:\tlearn: 0.4561529\ttotal: 2.89s\tremaining: 3.85s\n",
      "429:\tlearn: 0.4561057\ttotal: 2.9s\tremaining: 3.84s\n",
      "430:\tlearn: 0.4559743\ttotal: 2.9s\tremaining: 3.83s\n",
      "431:\tlearn: 0.4558655\ttotal: 2.91s\tremaining: 3.83s\n",
      "432:\tlearn: 0.4557486\ttotal: 2.92s\tremaining: 3.82s\n",
      "433:\tlearn: 0.4555709\ttotal: 2.92s\tremaining: 3.81s\n",
      "434:\tlearn: 0.4555557\ttotal: 2.93s\tremaining: 3.81s\n",
      "435:\tlearn: 0.4553959\ttotal: 2.94s\tremaining: 3.8s\n",
      "436:\tlearn: 0.4552633\ttotal: 2.94s\tremaining: 3.79s\n",
      "437:\tlearn: 0.4550903\ttotal: 2.95s\tremaining: 3.79s\n",
      "438:\tlearn: 0.4549739\ttotal: 2.96s\tremaining: 3.78s\n",
      "439:\tlearn: 0.4548537\ttotal: 2.96s\tremaining: 3.77s\n",
      "440:\tlearn: 0.4547132\ttotal: 2.97s\tremaining: 3.77s\n",
      "441:\tlearn: 0.4546128\ttotal: 2.98s\tremaining: 3.76s\n",
      "442:\tlearn: 0.4545076\ttotal: 2.98s\tremaining: 3.75s\n",
      "443:\tlearn: 0.4543966\ttotal: 2.99s\tremaining: 3.74s\n",
      "444:\tlearn: 0.4542624\ttotal: 3s\tremaining: 3.73s\n",
      "445:\tlearn: 0.4541904\ttotal: 3s\tremaining: 3.73s\n",
      "446:\tlearn: 0.4540630\ttotal: 3.01s\tremaining: 3.72s\n",
      "447:\tlearn: 0.4539717\ttotal: 3.01s\tremaining: 3.71s\n",
      "448:\tlearn: 0.4538324\ttotal: 3.02s\tremaining: 3.71s\n",
      "449:\tlearn: 0.4536950\ttotal: 3.03s\tremaining: 3.7s\n",
      "450:\tlearn: 0.4535120\ttotal: 3.03s\tremaining: 3.69s\n",
      "451:\tlearn: 0.4533451\ttotal: 3.04s\tremaining: 3.69s\n",
      "452:\tlearn: 0.4532389\ttotal: 3.05s\tremaining: 3.68s\n",
      "453:\tlearn: 0.4531461\ttotal: 3.05s\tremaining: 3.67s\n",
      "454:\tlearn: 0.4530425\ttotal: 3.06s\tremaining: 3.66s\n",
      "455:\tlearn: 0.4529199\ttotal: 3.07s\tremaining: 3.66s\n",
      "456:\tlearn: 0.4527656\ttotal: 3.07s\tremaining: 3.65s\n",
      "457:\tlearn: 0.4526083\ttotal: 3.08s\tremaining: 3.65s\n",
      "458:\tlearn: 0.4524577\ttotal: 3.09s\tremaining: 3.64s\n",
      "459:\tlearn: 0.4523274\ttotal: 3.09s\tremaining: 3.63s\n",
      "460:\tlearn: 0.4521688\ttotal: 3.1s\tremaining: 3.63s\n",
      "461:\tlearn: 0.4520098\ttotal: 3.11s\tremaining: 3.62s\n",
      "462:\tlearn: 0.4518941\ttotal: 3.11s\tremaining: 3.61s\n",
      "463:\tlearn: 0.4517351\ttotal: 3.12s\tremaining: 3.61s\n",
      "464:\tlearn: 0.4516163\ttotal: 3.13s\tremaining: 3.6s\n",
      "465:\tlearn: 0.4515351\ttotal: 3.13s\tremaining: 3.59s\n",
      "466:\tlearn: 0.4514002\ttotal: 3.14s\tremaining: 3.58s\n",
      "467:\tlearn: 0.4513236\ttotal: 3.15s\tremaining: 3.58s\n",
      "468:\tlearn: 0.4512014\ttotal: 3.15s\tremaining: 3.57s\n",
      "469:\tlearn: 0.4511383\ttotal: 3.16s\tremaining: 3.56s\n",
      "470:\tlearn: 0.4509098\ttotal: 3.17s\tremaining: 3.56s\n",
      "471:\tlearn: 0.4507854\ttotal: 3.17s\tremaining: 3.55s\n",
      "472:\tlearn: 0.4506882\ttotal: 3.18s\tremaining: 3.54s\n",
      "473:\tlearn: 0.4505330\ttotal: 3.18s\tremaining: 3.53s\n",
      "474:\tlearn: 0.4504330\ttotal: 3.19s\tremaining: 3.53s\n",
      "475:\tlearn: 0.4502724\ttotal: 3.2s\tremaining: 3.52s\n",
      "476:\tlearn: 0.4501182\ttotal: 3.2s\tremaining: 3.51s\n",
      "477:\tlearn: 0.4500153\ttotal: 3.21s\tremaining: 3.5s\n",
      "478:\tlearn: 0.4498655\ttotal: 3.22s\tremaining: 3.5s\n",
      "479:\tlearn: 0.4497056\ttotal: 3.22s\tremaining: 3.49s\n",
      "480:\tlearn: 0.4495717\ttotal: 3.23s\tremaining: 3.48s\n",
      "481:\tlearn: 0.4494377\ttotal: 3.24s\tremaining: 3.48s\n",
      "482:\tlearn: 0.4493079\ttotal: 3.24s\tremaining: 3.47s\n",
      "483:\tlearn: 0.4491852\ttotal: 3.25s\tremaining: 3.46s\n",
      "484:\tlearn: 0.4490617\ttotal: 3.26s\tremaining: 3.46s\n",
      "485:\tlearn: 0.4489125\ttotal: 3.26s\tremaining: 3.45s\n",
      "486:\tlearn: 0.4487908\ttotal: 3.27s\tremaining: 3.44s\n",
      "487:\tlearn: 0.4486854\ttotal: 3.28s\tremaining: 3.44s\n",
      "488:\tlearn: 0.4485881\ttotal: 3.28s\tremaining: 3.43s\n",
      "489:\tlearn: 0.4484269\ttotal: 3.29s\tremaining: 3.43s\n",
      "490:\tlearn: 0.4483170\ttotal: 3.3s\tremaining: 3.42s\n",
      "491:\tlearn: 0.4481376\ttotal: 3.3s\tremaining: 3.41s\n",
      "492:\tlearn: 0.4480450\ttotal: 3.31s\tremaining: 3.4s\n",
      "493:\tlearn: 0.4478906\ttotal: 3.32s\tremaining: 3.4s\n",
      "494:\tlearn: 0.4478635\ttotal: 3.32s\tremaining: 3.39s\n",
      "495:\tlearn: 0.4476800\ttotal: 3.33s\tremaining: 3.38s\n",
      "496:\tlearn: 0.4475180\ttotal: 3.34s\tremaining: 3.38s\n",
      "497:\tlearn: 0.4473825\ttotal: 3.34s\tremaining: 3.37s\n",
      "498:\tlearn: 0.4472628\ttotal: 3.35s\tremaining: 3.36s\n",
      "499:\tlearn: 0.4471226\ttotal: 3.36s\tremaining: 3.36s\n",
      "500:\tlearn: 0.4469909\ttotal: 3.36s\tremaining: 3.35s\n",
      "501:\tlearn: 0.4468171\ttotal: 3.37s\tremaining: 3.34s\n",
      "502:\tlearn: 0.4467012\ttotal: 3.38s\tremaining: 3.33s\n",
      "503:\tlearn: 0.4465757\ttotal: 3.38s\tremaining: 3.33s\n",
      "504:\tlearn: 0.4464859\ttotal: 3.39s\tremaining: 3.32s\n",
      "505:\tlearn: 0.4463625\ttotal: 3.39s\tremaining: 3.31s\n",
      "506:\tlearn: 0.4462588\ttotal: 3.4s\tremaining: 3.31s\n",
      "507:\tlearn: 0.4461391\ttotal: 3.41s\tremaining: 3.3s\n",
      "508:\tlearn: 0.4459802\ttotal: 3.41s\tremaining: 3.29s\n",
      "509:\tlearn: 0.4458687\ttotal: 3.42s\tremaining: 3.29s\n",
      "510:\tlearn: 0.4457459\ttotal: 3.43s\tremaining: 3.28s\n",
      "511:\tlearn: 0.4456343\ttotal: 3.43s\tremaining: 3.27s\n",
      "512:\tlearn: 0.4454844\ttotal: 3.44s\tremaining: 3.27s\n",
      "513:\tlearn: 0.4453915\ttotal: 3.45s\tremaining: 3.26s\n",
      "514:\tlearn: 0.4452782\ttotal: 3.45s\tremaining: 3.25s\n",
      "515:\tlearn: 0.4452414\ttotal: 3.46s\tremaining: 3.25s\n",
      "516:\tlearn: 0.4451278\ttotal: 3.47s\tremaining: 3.24s\n",
      "517:\tlearn: 0.4449960\ttotal: 3.47s\tremaining: 3.23s\n",
      "518:\tlearn: 0.4448853\ttotal: 3.48s\tremaining: 3.23s\n",
      "519:\tlearn: 0.4447601\ttotal: 3.49s\tremaining: 3.22s\n",
      "520:\tlearn: 0.4446330\ttotal: 3.49s\tremaining: 3.21s\n",
      "521:\tlearn: 0.4444927\ttotal: 3.5s\tremaining: 3.21s\n",
      "522:\tlearn: 0.4443539\ttotal: 3.51s\tremaining: 3.2s\n",
      "523:\tlearn: 0.4441910\ttotal: 3.51s\tremaining: 3.19s\n",
      "524:\tlearn: 0.4440391\ttotal: 3.52s\tremaining: 3.19s\n",
      "525:\tlearn: 0.4439143\ttotal: 3.53s\tremaining: 3.18s\n",
      "526:\tlearn: 0.4437971\ttotal: 3.53s\tremaining: 3.17s\n",
      "527:\tlearn: 0.4436463\ttotal: 3.54s\tremaining: 3.17s\n",
      "528:\tlearn: 0.4434611\ttotal: 3.55s\tremaining: 3.16s\n",
      "529:\tlearn: 0.4432989\ttotal: 3.55s\tremaining: 3.15s\n",
      "530:\tlearn: 0.4432342\ttotal: 3.56s\tremaining: 3.14s\n",
      "531:\tlearn: 0.4431683\ttotal: 3.56s\tremaining: 3.13s\n",
      "532:\tlearn: 0.4430481\ttotal: 3.57s\tremaining: 3.13s\n",
      "533:\tlearn: 0.4429616\ttotal: 3.58s\tremaining: 3.12s\n",
      "534:\tlearn: 0.4428362\ttotal: 3.58s\tremaining: 3.12s\n",
      "535:\tlearn: 0.4426780\ttotal: 3.59s\tremaining: 3.11s\n",
      "536:\tlearn: 0.4424998\ttotal: 3.6s\tremaining: 3.1s\n",
      "537:\tlearn: 0.4423682\ttotal: 3.6s\tremaining: 3.09s\n",
      "538:\tlearn: 0.4421966\ttotal: 3.61s\tremaining: 3.09s\n",
      "539:\tlearn: 0.4420948\ttotal: 3.62s\tremaining: 3.08s\n",
      "540:\tlearn: 0.4419719\ttotal: 3.62s\tremaining: 3.07s\n",
      "541:\tlearn: 0.4418419\ttotal: 3.63s\tremaining: 3.07s\n",
      "542:\tlearn: 0.4417004\ttotal: 3.64s\tremaining: 3.06s\n",
      "543:\tlearn: 0.4415652\ttotal: 3.64s\tremaining: 3.05s\n",
      "544:\tlearn: 0.4414040\ttotal: 3.65s\tremaining: 3.05s\n",
      "545:\tlearn: 0.4412928\ttotal: 3.65s\tremaining: 3.04s\n",
      "546:\tlearn: 0.4411332\ttotal: 3.66s\tremaining: 3.03s\n",
      "547:\tlearn: 0.4410374\ttotal: 3.67s\tremaining: 3.03s\n",
      "548:\tlearn: 0.4409344\ttotal: 3.68s\tremaining: 3.02s\n",
      "549:\tlearn: 0.4408012\ttotal: 3.68s\tremaining: 3.01s\n",
      "550:\tlearn: 0.4407123\ttotal: 3.69s\tremaining: 3.01s\n",
      "551:\tlearn: 0.4405450\ttotal: 3.7s\tremaining: 3s\n",
      "552:\tlearn: 0.4403917\ttotal: 3.7s\tremaining: 2.99s\n",
      "553:\tlearn: 0.4403286\ttotal: 3.71s\tremaining: 2.99s\n",
      "554:\tlearn: 0.4402233\ttotal: 3.72s\tremaining: 2.98s\n",
      "555:\tlearn: 0.4401269\ttotal: 3.72s\tremaining: 2.97s\n",
      "556:\tlearn: 0.4400511\ttotal: 3.73s\tremaining: 2.97s\n",
      "557:\tlearn: 0.4399571\ttotal: 3.74s\tremaining: 2.96s\n",
      "558:\tlearn: 0.4398270\ttotal: 3.74s\tremaining: 2.95s\n",
      "559:\tlearn: 0.4397197\ttotal: 3.75s\tremaining: 2.95s\n",
      "560:\tlearn: 0.4395820\ttotal: 3.76s\tremaining: 2.94s\n",
      "561:\tlearn: 0.4394801\ttotal: 3.76s\tremaining: 2.93s\n",
      "562:\tlearn: 0.4393239\ttotal: 3.77s\tremaining: 2.92s\n",
      "563:\tlearn: 0.4392409\ttotal: 3.77s\tremaining: 2.92s\n",
      "564:\tlearn: 0.4391533\ttotal: 3.78s\tremaining: 2.91s\n",
      "565:\tlearn: 0.4390498\ttotal: 3.79s\tremaining: 2.9s\n",
      "566:\tlearn: 0.4389148\ttotal: 3.79s\tremaining: 2.9s\n",
      "567:\tlearn: 0.4387555\ttotal: 3.8s\tremaining: 2.89s\n",
      "568:\tlearn: 0.4386247\ttotal: 3.81s\tremaining: 2.88s\n",
      "569:\tlearn: 0.4385627\ttotal: 3.81s\tremaining: 2.88s\n",
      "570:\tlearn: 0.4384298\ttotal: 3.82s\tremaining: 2.87s\n",
      "571:\tlearn: 0.4383142\ttotal: 3.83s\tremaining: 2.86s\n",
      "572:\tlearn: 0.4381879\ttotal: 3.83s\tremaining: 2.86s\n",
      "573:\tlearn: 0.4380428\ttotal: 3.84s\tremaining: 2.85s\n",
      "574:\tlearn: 0.4378903\ttotal: 3.85s\tremaining: 2.84s\n",
      "575:\tlearn: 0.4377746\ttotal: 3.85s\tremaining: 2.83s\n",
      "576:\tlearn: 0.4376151\ttotal: 3.86s\tremaining: 2.83s\n",
      "577:\tlearn: 0.4374821\ttotal: 3.87s\tremaining: 2.82s\n",
      "578:\tlearn: 0.4373501\ttotal: 3.87s\tremaining: 2.81s\n",
      "579:\tlearn: 0.4372192\ttotal: 3.88s\tremaining: 2.81s\n",
      "580:\tlearn: 0.4371446\ttotal: 3.89s\tremaining: 2.8s\n",
      "581:\tlearn: 0.4370538\ttotal: 3.89s\tremaining: 2.79s\n",
      "582:\tlearn: 0.4369110\ttotal: 3.91s\tremaining: 2.79s\n",
      "583:\tlearn: 0.4368466\ttotal: 3.92s\tremaining: 2.79s\n",
      "584:\tlearn: 0.4367244\ttotal: 3.92s\tremaining: 2.78s\n",
      "585:\tlearn: 0.4366010\ttotal: 3.93s\tremaining: 2.78s\n",
      "586:\tlearn: 0.4364670\ttotal: 3.94s\tremaining: 2.77s\n",
      "587:\tlearn: 0.4363665\ttotal: 3.94s\tremaining: 2.76s\n",
      "588:\tlearn: 0.4362770\ttotal: 3.95s\tremaining: 2.75s\n",
      "589:\tlearn: 0.4361351\ttotal: 3.96s\tremaining: 2.75s\n",
      "590:\tlearn: 0.4360354\ttotal: 3.96s\tremaining: 2.74s\n",
      "591:\tlearn: 0.4359127\ttotal: 3.97s\tremaining: 2.73s\n",
      "592:\tlearn: 0.4358192\ttotal: 3.98s\tremaining: 2.73s\n",
      "593:\tlearn: 0.4356895\ttotal: 3.98s\tremaining: 2.72s\n",
      "594:\tlearn: 0.4355549\ttotal: 3.99s\tremaining: 2.71s\n",
      "595:\tlearn: 0.4353840\ttotal: 4s\tremaining: 2.71s\n",
      "596:\tlearn: 0.4352284\ttotal: 4s\tremaining: 2.7s\n",
      "597:\tlearn: 0.4350948\ttotal: 4.01s\tremaining: 2.69s\n",
      "598:\tlearn: 0.4349841\ttotal: 4.02s\tremaining: 2.69s\n",
      "599:\tlearn: 0.4348423\ttotal: 4.02s\tremaining: 2.68s\n",
      "600:\tlearn: 0.4347638\ttotal: 4.03s\tremaining: 2.67s\n",
      "601:\tlearn: 0.4346545\ttotal: 4.04s\tremaining: 2.67s\n",
      "602:\tlearn: 0.4344897\ttotal: 4.04s\tremaining: 2.66s\n",
      "603:\tlearn: 0.4343944\ttotal: 4.05s\tremaining: 2.65s\n",
      "604:\tlearn: 0.4342741\ttotal: 4.05s\tremaining: 2.65s\n",
      "605:\tlearn: 0.4341488\ttotal: 4.06s\tremaining: 2.64s\n",
      "606:\tlearn: 0.4339466\ttotal: 4.07s\tremaining: 2.63s\n",
      "607:\tlearn: 0.4338689\ttotal: 4.07s\tremaining: 2.63s\n",
      "608:\tlearn: 0.4337041\ttotal: 4.08s\tremaining: 2.62s\n",
      "609:\tlearn: 0.4335477\ttotal: 4.09s\tremaining: 2.61s\n",
      "610:\tlearn: 0.4333995\ttotal: 4.09s\tremaining: 2.61s\n",
      "611:\tlearn: 0.4332938\ttotal: 4.1s\tremaining: 2.6s\n",
      "612:\tlearn: 0.4331247\ttotal: 4.11s\tremaining: 2.59s\n",
      "613:\tlearn: 0.4329467\ttotal: 4.11s\tremaining: 2.59s\n",
      "614:\tlearn: 0.4328884\ttotal: 4.12s\tremaining: 2.58s\n",
      "615:\tlearn: 0.4327483\ttotal: 4.13s\tremaining: 2.57s\n",
      "616:\tlearn: 0.4326330\ttotal: 4.13s\tremaining: 2.56s\n",
      "617:\tlearn: 0.4325009\ttotal: 4.14s\tremaining: 2.56s\n",
      "618:\tlearn: 0.4323578\ttotal: 4.15s\tremaining: 2.55s\n",
      "619:\tlearn: 0.4322564\ttotal: 4.15s\tremaining: 2.54s\n",
      "620:\tlearn: 0.4321266\ttotal: 4.16s\tremaining: 2.54s\n",
      "621:\tlearn: 0.4320038\ttotal: 4.17s\tremaining: 2.53s\n",
      "622:\tlearn: 0.4319086\ttotal: 4.17s\tremaining: 2.52s\n",
      "623:\tlearn: 0.4317736\ttotal: 4.18s\tremaining: 2.52s\n",
      "624:\tlearn: 0.4316407\ttotal: 4.18s\tremaining: 2.51s\n",
      "625:\tlearn: 0.4315572\ttotal: 4.19s\tremaining: 2.5s\n",
      "626:\tlearn: 0.4314339\ttotal: 4.2s\tremaining: 2.5s\n",
      "627:\tlearn: 0.4312618\ttotal: 4.2s\tremaining: 2.49s\n",
      "628:\tlearn: 0.4311412\ttotal: 4.21s\tremaining: 2.48s\n",
      "629:\tlearn: 0.4310339\ttotal: 4.21s\tremaining: 2.48s\n",
      "630:\tlearn: 0.4309137\ttotal: 4.22s\tremaining: 2.47s\n",
      "631:\tlearn: 0.4308339\ttotal: 4.23s\tremaining: 2.46s\n",
      "632:\tlearn: 0.4307098\ttotal: 4.24s\tremaining: 2.46s\n",
      "633:\tlearn: 0.4305617\ttotal: 4.24s\tremaining: 2.45s\n",
      "634:\tlearn: 0.4304322\ttotal: 4.25s\tremaining: 2.44s\n",
      "635:\tlearn: 0.4303182\ttotal: 4.25s\tremaining: 2.44s\n",
      "636:\tlearn: 0.4301615\ttotal: 4.26s\tremaining: 2.43s\n",
      "637:\tlearn: 0.4300465\ttotal: 4.27s\tremaining: 2.42s\n",
      "638:\tlearn: 0.4299061\ttotal: 4.28s\tremaining: 2.42s\n",
      "639:\tlearn: 0.4298130\ttotal: 4.28s\tremaining: 2.41s\n",
      "640:\tlearn: 0.4296680\ttotal: 4.29s\tremaining: 2.4s\n",
      "641:\tlearn: 0.4295884\ttotal: 4.29s\tremaining: 2.39s\n",
      "642:\tlearn: 0.4294730\ttotal: 4.3s\tremaining: 2.39s\n",
      "643:\tlearn: 0.4293471\ttotal: 4.31s\tremaining: 2.38s\n",
      "644:\tlearn: 0.4291911\ttotal: 4.32s\tremaining: 2.38s\n",
      "645:\tlearn: 0.4290668\ttotal: 4.32s\tremaining: 2.37s\n",
      "646:\tlearn: 0.4289482\ttotal: 4.33s\tremaining: 2.36s\n",
      "647:\tlearn: 0.4288324\ttotal: 4.34s\tremaining: 2.35s\n",
      "648:\tlearn: 0.4286582\ttotal: 4.34s\tremaining: 2.35s\n",
      "649:\tlearn: 0.4285785\ttotal: 4.35s\tremaining: 2.34s\n",
      "650:\tlearn: 0.4284792\ttotal: 4.36s\tremaining: 2.33s\n",
      "651:\tlearn: 0.4283610\ttotal: 4.36s\tremaining: 2.33s\n",
      "652:\tlearn: 0.4282215\ttotal: 4.37s\tremaining: 2.32s\n",
      "653:\tlearn: 0.4281177\ttotal: 4.38s\tremaining: 2.31s\n",
      "654:\tlearn: 0.4279415\ttotal: 4.38s\tremaining: 2.31s\n",
      "655:\tlearn: 0.4277980\ttotal: 4.39s\tremaining: 2.3s\n",
      "656:\tlearn: 0.4276644\ttotal: 4.39s\tremaining: 2.29s\n",
      "657:\tlearn: 0.4275703\ttotal: 4.4s\tremaining: 2.29s\n",
      "658:\tlearn: 0.4274357\ttotal: 4.41s\tremaining: 2.28s\n",
      "659:\tlearn: 0.4273447\ttotal: 4.42s\tremaining: 2.27s\n",
      "660:\tlearn: 0.4272342\ttotal: 4.42s\tremaining: 2.27s\n",
      "661:\tlearn: 0.4270862\ttotal: 4.43s\tremaining: 2.26s\n",
      "662:\tlearn: 0.4270238\ttotal: 4.44s\tremaining: 2.25s\n",
      "663:\tlearn: 0.4269507\ttotal: 4.44s\tremaining: 2.25s\n",
      "664:\tlearn: 0.4268433\ttotal: 4.45s\tremaining: 2.24s\n",
      "665:\tlearn: 0.4267275\ttotal: 4.46s\tremaining: 2.23s\n",
      "666:\tlearn: 0.4265894\ttotal: 4.46s\tremaining: 2.23s\n",
      "667:\tlearn: 0.4264950\ttotal: 4.47s\tremaining: 2.22s\n",
      "668:\tlearn: 0.4263513\ttotal: 4.48s\tremaining: 2.21s\n",
      "669:\tlearn: 0.4263075\ttotal: 4.48s\tremaining: 2.21s\n",
      "670:\tlearn: 0.4262065\ttotal: 4.49s\tremaining: 2.2s\n",
      "671:\tlearn: 0.4260763\ttotal: 4.5s\tremaining: 2.19s\n",
      "672:\tlearn: 0.4259715\ttotal: 4.5s\tremaining: 2.19s\n",
      "673:\tlearn: 0.4258857\ttotal: 4.51s\tremaining: 2.18s\n",
      "674:\tlearn: 0.4257726\ttotal: 4.51s\tremaining: 2.17s\n",
      "675:\tlearn: 0.4256834\ttotal: 4.52s\tremaining: 2.17s\n",
      "676:\tlearn: 0.4255742\ttotal: 4.53s\tremaining: 2.16s\n",
      "677:\tlearn: 0.4254721\ttotal: 4.53s\tremaining: 2.15s\n",
      "678:\tlearn: 0.4253602\ttotal: 4.54s\tremaining: 2.15s\n",
      "679:\tlearn: 0.4252558\ttotal: 4.55s\tremaining: 2.14s\n",
      "680:\tlearn: 0.4251153\ttotal: 4.55s\tremaining: 2.13s\n",
      "681:\tlearn: 0.4250522\ttotal: 4.56s\tremaining: 2.13s\n",
      "682:\tlearn: 0.4249050\ttotal: 4.57s\tremaining: 2.12s\n",
      "683:\tlearn: 0.4248346\ttotal: 4.57s\tremaining: 2.11s\n",
      "684:\tlearn: 0.4247009\ttotal: 4.58s\tremaining: 2.1s\n",
      "685:\tlearn: 0.4245486\ttotal: 4.58s\tremaining: 2.1s\n",
      "686:\tlearn: 0.4244075\ttotal: 4.59s\tremaining: 2.09s\n",
      "687:\tlearn: 0.4242480\ttotal: 4.6s\tremaining: 2.08s\n",
      "688:\tlearn: 0.4241214\ttotal: 4.61s\tremaining: 2.08s\n",
      "689:\tlearn: 0.4240268\ttotal: 4.61s\tremaining: 2.07s\n",
      "690:\tlearn: 0.4239269\ttotal: 4.62s\tremaining: 2.06s\n",
      "691:\tlearn: 0.4238029\ttotal: 4.62s\tremaining: 2.06s\n",
      "692:\tlearn: 0.4236688\ttotal: 4.63s\tremaining: 2.05s\n",
      "693:\tlearn: 0.4235893\ttotal: 4.64s\tremaining: 2.04s\n",
      "694:\tlearn: 0.4234744\ttotal: 4.64s\tremaining: 2.04s\n",
      "695:\tlearn: 0.4233747\ttotal: 4.65s\tremaining: 2.03s\n",
      "696:\tlearn: 0.4232518\ttotal: 4.65s\tremaining: 2.02s\n",
      "697:\tlearn: 0.4231170\ttotal: 4.66s\tremaining: 2.02s\n",
      "698:\tlearn: 0.4229358\ttotal: 4.67s\tremaining: 2.01s\n",
      "699:\tlearn: 0.4228122\ttotal: 4.67s\tremaining: 2s\n",
      "700:\tlearn: 0.4226631\ttotal: 4.68s\tremaining: 2s\n",
      "701:\tlearn: 0.4225436\ttotal: 4.69s\tremaining: 1.99s\n",
      "702:\tlearn: 0.4224138\ttotal: 4.69s\tremaining: 1.98s\n",
      "703:\tlearn: 0.4223313\ttotal: 4.7s\tremaining: 1.98s\n",
      "704:\tlearn: 0.4221909\ttotal: 4.71s\tremaining: 1.97s\n",
      "705:\tlearn: 0.4220802\ttotal: 4.71s\tremaining: 1.96s\n",
      "706:\tlearn: 0.4220315\ttotal: 4.72s\tremaining: 1.96s\n",
      "707:\tlearn: 0.4219173\ttotal: 4.73s\tremaining: 1.95s\n",
      "708:\tlearn: 0.4217913\ttotal: 4.74s\tremaining: 1.94s\n",
      "709:\tlearn: 0.4217279\ttotal: 4.74s\tremaining: 1.94s\n",
      "710:\tlearn: 0.4215901\ttotal: 4.75s\tremaining: 1.93s\n",
      "711:\tlearn: 0.4214617\ttotal: 4.75s\tremaining: 1.92s\n",
      "712:\tlearn: 0.4213501\ttotal: 4.76s\tremaining: 1.92s\n",
      "713:\tlearn: 0.4212033\ttotal: 4.77s\tremaining: 1.91s\n",
      "714:\tlearn: 0.4210813\ttotal: 4.77s\tremaining: 1.9s\n",
      "715:\tlearn: 0.4209603\ttotal: 4.78s\tremaining: 1.9s\n",
      "716:\tlearn: 0.4208388\ttotal: 4.79s\tremaining: 1.89s\n",
      "717:\tlearn: 0.4207814\ttotal: 4.79s\tremaining: 1.88s\n",
      "718:\tlearn: 0.4206793\ttotal: 4.8s\tremaining: 1.88s\n",
      "719:\tlearn: 0.4206157\ttotal: 4.8s\tremaining: 1.87s\n",
      "720:\tlearn: 0.4205055\ttotal: 4.81s\tremaining: 1.86s\n",
      "721:\tlearn: 0.4203600\ttotal: 4.82s\tremaining: 1.85s\n",
      "722:\tlearn: 0.4202200\ttotal: 4.82s\tremaining: 1.85s\n",
      "723:\tlearn: 0.4200884\ttotal: 4.83s\tremaining: 1.84s\n",
      "724:\tlearn: 0.4200125\ttotal: 4.84s\tremaining: 1.83s\n",
      "725:\tlearn: 0.4198395\ttotal: 4.84s\tremaining: 1.83s\n",
      "726:\tlearn: 0.4197322\ttotal: 4.85s\tremaining: 1.82s\n",
      "727:\tlearn: 0.4196143\ttotal: 4.86s\tremaining: 1.81s\n",
      "728:\tlearn: 0.4194941\ttotal: 4.86s\tremaining: 1.81s\n",
      "729:\tlearn: 0.4193688\ttotal: 4.87s\tremaining: 1.8s\n",
      "730:\tlearn: 0.4192387\ttotal: 4.88s\tremaining: 1.79s\n",
      "731:\tlearn: 0.4191677\ttotal: 4.88s\tremaining: 1.79s\n",
      "732:\tlearn: 0.4190614\ttotal: 4.89s\tremaining: 1.78s\n",
      "733:\tlearn: 0.4189186\ttotal: 4.9s\tremaining: 1.77s\n",
      "734:\tlearn: 0.4188211\ttotal: 4.9s\tremaining: 1.77s\n",
      "735:\tlearn: 0.4187151\ttotal: 4.91s\tremaining: 1.76s\n",
      "736:\tlearn: 0.4186049\ttotal: 4.92s\tremaining: 1.75s\n",
      "737:\tlearn: 0.4184938\ttotal: 4.92s\tremaining: 1.75s\n",
      "738:\tlearn: 0.4183817\ttotal: 4.93s\tremaining: 1.74s\n",
      "739:\tlearn: 0.4182898\ttotal: 4.94s\tremaining: 1.73s\n",
      "740:\tlearn: 0.4181086\ttotal: 4.94s\tremaining: 1.73s\n",
      "741:\tlearn: 0.4180082\ttotal: 4.95s\tremaining: 1.72s\n",
      "742:\tlearn: 0.4178793\ttotal: 4.96s\tremaining: 1.71s\n",
      "743:\tlearn: 0.4177464\ttotal: 4.96s\tremaining: 1.71s\n",
      "744:\tlearn: 0.4176020\ttotal: 4.97s\tremaining: 1.7s\n",
      "745:\tlearn: 0.4174854\ttotal: 4.97s\tremaining: 1.69s\n",
      "746:\tlearn: 0.4173279\ttotal: 4.98s\tremaining: 1.69s\n",
      "747:\tlearn: 0.4171996\ttotal: 4.99s\tremaining: 1.68s\n",
      "748:\tlearn: 0.4171257\ttotal: 4.99s\tremaining: 1.67s\n",
      "749:\tlearn: 0.4170245\ttotal: 5s\tremaining: 1.67s\n",
      "750:\tlearn: 0.4168955\ttotal: 5.01s\tremaining: 1.66s\n",
      "751:\tlearn: 0.4168108\ttotal: 5.01s\tremaining: 1.65s\n",
      "752:\tlearn: 0.4167300\ttotal: 5.02s\tremaining: 1.65s\n",
      "753:\tlearn: 0.4166396\ttotal: 5.03s\tremaining: 1.64s\n",
      "754:\tlearn: 0.4164815\ttotal: 5.03s\tremaining: 1.63s\n",
      "755:\tlearn: 0.4163827\ttotal: 5.04s\tremaining: 1.63s\n",
      "756:\tlearn: 0.4162496\ttotal: 5.05s\tremaining: 1.62s\n",
      "757:\tlearn: 0.4161508\ttotal: 5.05s\tremaining: 1.61s\n",
      "758:\tlearn: 0.4160672\ttotal: 5.06s\tremaining: 1.61s\n",
      "759:\tlearn: 0.4159787\ttotal: 5.07s\tremaining: 1.6s\n",
      "760:\tlearn: 0.4158365\ttotal: 5.07s\tremaining: 1.59s\n",
      "761:\tlearn: 0.4157913\ttotal: 5.08s\tremaining: 1.59s\n",
      "762:\tlearn: 0.4156755\ttotal: 5.09s\tremaining: 1.58s\n",
      "763:\tlearn: 0.4155094\ttotal: 5.1s\tremaining: 1.57s\n",
      "764:\tlearn: 0.4153951\ttotal: 5.11s\tremaining: 1.57s\n",
      "765:\tlearn: 0.4152863\ttotal: 5.11s\tremaining: 1.56s\n",
      "766:\tlearn: 0.4152093\ttotal: 5.12s\tremaining: 1.55s\n",
      "767:\tlearn: 0.4151177\ttotal: 5.13s\tremaining: 1.55s\n",
      "768:\tlearn: 0.4150235\ttotal: 5.14s\tremaining: 1.54s\n",
      "769:\tlearn: 0.4149123\ttotal: 5.14s\tremaining: 1.54s\n",
      "770:\tlearn: 0.4147541\ttotal: 5.15s\tremaining: 1.53s\n",
      "771:\tlearn: 0.4146706\ttotal: 5.16s\tremaining: 1.52s\n",
      "772:\tlearn: 0.4145195\ttotal: 5.16s\tremaining: 1.51s\n",
      "773:\tlearn: 0.4144427\ttotal: 5.17s\tremaining: 1.51s\n",
      "774:\tlearn: 0.4143658\ttotal: 5.17s\tremaining: 1.5s\n",
      "775:\tlearn: 0.4142353\ttotal: 5.18s\tremaining: 1.5s\n",
      "776:\tlearn: 0.4141390\ttotal: 5.19s\tremaining: 1.49s\n",
      "777:\tlearn: 0.4140348\ttotal: 5.19s\tremaining: 1.48s\n",
      "778:\tlearn: 0.4139275\ttotal: 5.2s\tremaining: 1.48s\n",
      "779:\tlearn: 0.4138109\ttotal: 5.21s\tremaining: 1.47s\n",
      "780:\tlearn: 0.4136696\ttotal: 5.21s\tremaining: 1.46s\n",
      "781:\tlearn: 0.4135547\ttotal: 5.22s\tremaining: 1.45s\n",
      "782:\tlearn: 0.4134133\ttotal: 5.22s\tremaining: 1.45s\n",
      "783:\tlearn: 0.4132899\ttotal: 5.23s\tremaining: 1.44s\n",
      "784:\tlearn: 0.4131618\ttotal: 5.24s\tremaining: 1.43s\n",
      "785:\tlearn: 0.4130559\ttotal: 5.24s\tremaining: 1.43s\n",
      "786:\tlearn: 0.4129153\ttotal: 5.25s\tremaining: 1.42s\n",
      "787:\tlearn: 0.4128645\ttotal: 5.26s\tremaining: 1.41s\n",
      "788:\tlearn: 0.4127286\ttotal: 5.26s\tremaining: 1.41s\n",
      "789:\tlearn: 0.4125813\ttotal: 5.27s\tremaining: 1.4s\n",
      "790:\tlearn: 0.4124769\ttotal: 5.28s\tremaining: 1.39s\n",
      "791:\tlearn: 0.4123705\ttotal: 5.28s\tremaining: 1.39s\n",
      "792:\tlearn: 0.4123111\ttotal: 5.29s\tremaining: 1.38s\n",
      "793:\tlearn: 0.4121868\ttotal: 5.3s\tremaining: 1.37s\n",
      "794:\tlearn: 0.4121060\ttotal: 5.3s\tremaining: 1.37s\n",
      "795:\tlearn: 0.4119860\ttotal: 5.31s\tremaining: 1.36s\n",
      "796:\tlearn: 0.4118882\ttotal: 5.32s\tremaining: 1.35s\n",
      "797:\tlearn: 0.4117594\ttotal: 5.32s\tremaining: 1.35s\n",
      "798:\tlearn: 0.4116723\ttotal: 5.33s\tremaining: 1.34s\n",
      "799:\tlearn: 0.4115045\ttotal: 5.34s\tremaining: 1.33s\n",
      "800:\tlearn: 0.4113598\ttotal: 5.34s\tremaining: 1.33s\n",
      "801:\tlearn: 0.4112501\ttotal: 5.35s\tremaining: 1.32s\n",
      "802:\tlearn: 0.4111801\ttotal: 5.36s\tremaining: 1.31s\n",
      "803:\tlearn: 0.4110582\ttotal: 5.36s\tremaining: 1.31s\n",
      "804:\tlearn: 0.4109961\ttotal: 5.37s\tremaining: 1.3s\n",
      "805:\tlearn: 0.4109031\ttotal: 5.38s\tremaining: 1.29s\n",
      "806:\tlearn: 0.4108004\ttotal: 5.38s\tremaining: 1.29s\n",
      "807:\tlearn: 0.4106764\ttotal: 5.39s\tremaining: 1.28s\n",
      "808:\tlearn: 0.4105682\ttotal: 5.39s\tremaining: 1.27s\n",
      "809:\tlearn: 0.4104381\ttotal: 5.4s\tremaining: 1.27s\n",
      "810:\tlearn: 0.4103290\ttotal: 5.41s\tremaining: 1.26s\n",
      "811:\tlearn: 0.4102545\ttotal: 5.41s\tremaining: 1.25s\n",
      "812:\tlearn: 0.4100747\ttotal: 5.42s\tremaining: 1.25s\n",
      "813:\tlearn: 0.4099647\ttotal: 5.43s\tremaining: 1.24s\n",
      "814:\tlearn: 0.4098729\ttotal: 5.43s\tremaining: 1.23s\n",
      "815:\tlearn: 0.4097724\ttotal: 5.44s\tremaining: 1.23s\n",
      "816:\tlearn: 0.4096950\ttotal: 5.45s\tremaining: 1.22s\n",
      "817:\tlearn: 0.4095943\ttotal: 5.45s\tremaining: 1.21s\n",
      "818:\tlearn: 0.4094967\ttotal: 5.46s\tremaining: 1.21s\n",
      "819:\tlearn: 0.4094480\ttotal: 5.46s\tremaining: 1.2s\n",
      "820:\tlearn: 0.4093527\ttotal: 5.47s\tremaining: 1.19s\n",
      "821:\tlearn: 0.4092426\ttotal: 5.48s\tremaining: 1.19s\n",
      "822:\tlearn: 0.4091499\ttotal: 5.49s\tremaining: 1.18s\n",
      "823:\tlearn: 0.4090246\ttotal: 5.49s\tremaining: 1.17s\n",
      "824:\tlearn: 0.4089484\ttotal: 5.5s\tremaining: 1.17s\n",
      "825:\tlearn: 0.4088480\ttotal: 5.51s\tremaining: 1.16s\n",
      "826:\tlearn: 0.4087647\ttotal: 5.51s\tremaining: 1.15s\n",
      "827:\tlearn: 0.4086885\ttotal: 5.52s\tremaining: 1.15s\n",
      "828:\tlearn: 0.4085997\ttotal: 5.53s\tremaining: 1.14s\n",
      "829:\tlearn: 0.4084682\ttotal: 5.53s\tremaining: 1.13s\n",
      "830:\tlearn: 0.4083685\ttotal: 5.54s\tremaining: 1.13s\n",
      "831:\tlearn: 0.4082606\ttotal: 5.55s\tremaining: 1.12s\n",
      "832:\tlearn: 0.4081126\ttotal: 5.55s\tremaining: 1.11s\n",
      "833:\tlearn: 0.4079878\ttotal: 5.56s\tremaining: 1.11s\n",
      "834:\tlearn: 0.4078503\ttotal: 5.57s\tremaining: 1.1s\n",
      "835:\tlearn: 0.4077533\ttotal: 5.58s\tremaining: 1.09s\n",
      "836:\tlearn: 0.4076082\ttotal: 5.58s\tremaining: 1.09s\n",
      "837:\tlearn: 0.4075115\ttotal: 5.59s\tremaining: 1.08s\n",
      "838:\tlearn: 0.4074167\ttotal: 5.59s\tremaining: 1.07s\n",
      "839:\tlearn: 0.4073225\ttotal: 5.6s\tremaining: 1.07s\n",
      "840:\tlearn: 0.4072292\ttotal: 5.61s\tremaining: 1.06s\n",
      "841:\tlearn: 0.4071112\ttotal: 5.61s\tremaining: 1.05s\n",
      "842:\tlearn: 0.4070282\ttotal: 5.62s\tremaining: 1.05s\n",
      "843:\tlearn: 0.4069092\ttotal: 5.63s\tremaining: 1.04s\n",
      "844:\tlearn: 0.4067816\ttotal: 5.63s\tremaining: 1.03s\n",
      "845:\tlearn: 0.4066998\ttotal: 5.64s\tremaining: 1.03s\n",
      "846:\tlearn: 0.4065367\ttotal: 5.65s\tremaining: 1.02s\n",
      "847:\tlearn: 0.4064176\ttotal: 5.65s\tremaining: 1.01s\n",
      "848:\tlearn: 0.4063019\ttotal: 5.66s\tremaining: 1.01s\n",
      "849:\tlearn: 0.4061916\ttotal: 5.67s\tremaining: 1000ms\n",
      "850:\tlearn: 0.4060535\ttotal: 5.67s\tremaining: 993ms\n",
      "851:\tlearn: 0.4060066\ttotal: 5.68s\tremaining: 986ms\n",
      "852:\tlearn: 0.4059044\ttotal: 5.68s\tremaining: 980ms\n",
      "853:\tlearn: 0.4057812\ttotal: 5.69s\tremaining: 973ms\n",
      "854:\tlearn: 0.4056672\ttotal: 5.7s\tremaining: 966ms\n",
      "855:\tlearn: 0.4055405\ttotal: 5.7s\tremaining: 960ms\n",
      "856:\tlearn: 0.4054408\ttotal: 5.71s\tremaining: 953ms\n",
      "857:\tlearn: 0.4052843\ttotal: 5.72s\tremaining: 946ms\n",
      "858:\tlearn: 0.4051758\ttotal: 5.72s\tremaining: 940ms\n",
      "859:\tlearn: 0.4050683\ttotal: 5.73s\tremaining: 933ms\n",
      "860:\tlearn: 0.4049938\ttotal: 5.74s\tremaining: 926ms\n",
      "861:\tlearn: 0.4048640\ttotal: 5.75s\tremaining: 920ms\n",
      "862:\tlearn: 0.4047356\ttotal: 5.75s\tremaining: 913ms\n",
      "863:\tlearn: 0.4046490\ttotal: 5.76s\tremaining: 906ms\n",
      "864:\tlearn: 0.4045347\ttotal: 5.76s\tremaining: 900ms\n",
      "865:\tlearn: 0.4044070\ttotal: 5.77s\tremaining: 893ms\n",
      "866:\tlearn: 0.4042808\ttotal: 5.78s\tremaining: 886ms\n",
      "867:\tlearn: 0.4041795\ttotal: 5.78s\tremaining: 880ms\n",
      "868:\tlearn: 0.4040994\ttotal: 5.79s\tremaining: 873ms\n",
      "869:\tlearn: 0.4039935\ttotal: 5.8s\tremaining: 866ms\n",
      "870:\tlearn: 0.4038647\ttotal: 5.8s\tremaining: 860ms\n",
      "871:\tlearn: 0.4037502\ttotal: 5.81s\tremaining: 853ms\n",
      "872:\tlearn: 0.4036797\ttotal: 5.82s\tremaining: 846ms\n",
      "873:\tlearn: 0.4036167\ttotal: 5.82s\tremaining: 839ms\n",
      "874:\tlearn: 0.4035362\ttotal: 5.83s\tremaining: 833ms\n",
      "875:\tlearn: 0.4034375\ttotal: 5.83s\tremaining: 826ms\n",
      "876:\tlearn: 0.4032948\ttotal: 5.84s\tremaining: 819ms\n",
      "877:\tlearn: 0.4031347\ttotal: 5.85s\tremaining: 813ms\n",
      "878:\tlearn: 0.4030203\ttotal: 5.85s\tremaining: 806ms\n",
      "879:\tlearn: 0.4029241\ttotal: 5.86s\tremaining: 799ms\n",
      "880:\tlearn: 0.4028888\ttotal: 5.87s\tremaining: 792ms\n",
      "881:\tlearn: 0.4027987\ttotal: 5.87s\tremaining: 786ms\n",
      "882:\tlearn: 0.4027235\ttotal: 5.88s\tremaining: 779ms\n",
      "883:\tlearn: 0.4026567\ttotal: 5.88s\tremaining: 772ms\n",
      "884:\tlearn: 0.4025669\ttotal: 5.89s\tremaining: 766ms\n",
      "885:\tlearn: 0.4024821\ttotal: 5.9s\tremaining: 759ms\n",
      "886:\tlearn: 0.4023411\ttotal: 5.9s\tremaining: 752ms\n",
      "887:\tlearn: 0.4022171\ttotal: 5.91s\tremaining: 746ms\n",
      "888:\tlearn: 0.4020964\ttotal: 5.92s\tremaining: 739ms\n",
      "889:\tlearn: 0.4020161\ttotal: 5.92s\tremaining: 732ms\n",
      "890:\tlearn: 0.4019413\ttotal: 5.93s\tremaining: 725ms\n",
      "891:\tlearn: 0.4018414\ttotal: 5.94s\tremaining: 719ms\n",
      "892:\tlearn: 0.4017153\ttotal: 5.94s\tremaining: 712ms\n",
      "893:\tlearn: 0.4016102\ttotal: 5.95s\tremaining: 705ms\n",
      "894:\tlearn: 0.4015338\ttotal: 5.96s\tremaining: 699ms\n",
      "895:\tlearn: 0.4014275\ttotal: 5.96s\tremaining: 692ms\n",
      "896:\tlearn: 0.4013550\ttotal: 5.97s\tremaining: 685ms\n",
      "897:\tlearn: 0.4013050\ttotal: 5.97s\tremaining: 679ms\n",
      "898:\tlearn: 0.4011913\ttotal: 5.98s\tremaining: 672ms\n",
      "899:\tlearn: 0.4010957\ttotal: 5.99s\tremaining: 665ms\n",
      "900:\tlearn: 0.4010132\ttotal: 5.99s\tremaining: 659ms\n",
      "901:\tlearn: 0.4009267\ttotal: 6s\tremaining: 652ms\n",
      "902:\tlearn: 0.4008257\ttotal: 6s\tremaining: 645ms\n",
      "903:\tlearn: 0.4006989\ttotal: 6.01s\tremaining: 638ms\n",
      "904:\tlearn: 0.4005659\ttotal: 6.02s\tremaining: 632ms\n",
      "905:\tlearn: 0.4004936\ttotal: 6.03s\tremaining: 625ms\n",
      "906:\tlearn: 0.4003247\ttotal: 6.03s\tremaining: 618ms\n",
      "907:\tlearn: 0.4001703\ttotal: 6.04s\tremaining: 612ms\n",
      "908:\tlearn: 0.4000577\ttotal: 6.04s\tremaining: 605ms\n",
      "909:\tlearn: 0.3999094\ttotal: 6.05s\tremaining: 598ms\n",
      "910:\tlearn: 0.3998041\ttotal: 6.06s\tremaining: 592ms\n",
      "911:\tlearn: 0.3997105\ttotal: 6.07s\tremaining: 585ms\n",
      "912:\tlearn: 0.3995731\ttotal: 6.07s\tremaining: 579ms\n",
      "913:\tlearn: 0.3994299\ttotal: 6.08s\tremaining: 572ms\n",
      "914:\tlearn: 0.3993722\ttotal: 6.08s\tremaining: 565ms\n",
      "915:\tlearn: 0.3992467\ttotal: 6.09s\tremaining: 558ms\n",
      "916:\tlearn: 0.3991089\ttotal: 6.1s\tremaining: 552ms\n",
      "917:\tlearn: 0.3989663\ttotal: 6.1s\tremaining: 545ms\n",
      "918:\tlearn: 0.3988483\ttotal: 6.11s\tremaining: 538ms\n",
      "919:\tlearn: 0.3987262\ttotal: 6.12s\tremaining: 532ms\n",
      "920:\tlearn: 0.3986508\ttotal: 6.12s\tremaining: 525ms\n",
      "921:\tlearn: 0.3985236\ttotal: 6.13s\tremaining: 518ms\n",
      "922:\tlearn: 0.3984654\ttotal: 6.13s\tremaining: 512ms\n",
      "923:\tlearn: 0.3983642\ttotal: 6.14s\tremaining: 505ms\n",
      "924:\tlearn: 0.3982696\ttotal: 6.15s\tremaining: 498ms\n",
      "925:\tlearn: 0.3981717\ttotal: 6.15s\tremaining: 492ms\n",
      "926:\tlearn: 0.3980458\ttotal: 6.16s\tremaining: 485ms\n",
      "927:\tlearn: 0.3979509\ttotal: 6.17s\tremaining: 478ms\n",
      "928:\tlearn: 0.3978100\ttotal: 6.17s\tremaining: 472ms\n",
      "929:\tlearn: 0.3977114\ttotal: 6.18s\tremaining: 465ms\n",
      "930:\tlearn: 0.3975634\ttotal: 6.18s\tremaining: 458ms\n",
      "931:\tlearn: 0.3974376\ttotal: 6.19s\tremaining: 452ms\n",
      "932:\tlearn: 0.3973645\ttotal: 6.2s\tremaining: 445ms\n",
      "933:\tlearn: 0.3972326\ttotal: 6.2s\tremaining: 438ms\n",
      "934:\tlearn: 0.3971441\ttotal: 6.21s\tremaining: 432ms\n",
      "935:\tlearn: 0.3970375\ttotal: 6.22s\tremaining: 425ms\n",
      "936:\tlearn: 0.3968986\ttotal: 6.22s\tremaining: 418ms\n",
      "937:\tlearn: 0.3967475\ttotal: 6.23s\tremaining: 412ms\n",
      "938:\tlearn: 0.3966291\ttotal: 6.24s\tremaining: 405ms\n",
      "939:\tlearn: 0.3965448\ttotal: 6.24s\tremaining: 398ms\n",
      "940:\tlearn: 0.3964300\ttotal: 6.25s\tremaining: 392ms\n",
      "941:\tlearn: 0.3963092\ttotal: 6.25s\tremaining: 385ms\n",
      "942:\tlearn: 0.3962188\ttotal: 6.26s\tremaining: 378ms\n",
      "943:\tlearn: 0.3960686\ttotal: 6.27s\tremaining: 372ms\n",
      "944:\tlearn: 0.3959510\ttotal: 6.27s\tremaining: 365ms\n",
      "945:\tlearn: 0.3957922\ttotal: 6.28s\tremaining: 358ms\n",
      "946:\tlearn: 0.3956423\ttotal: 6.29s\tremaining: 352ms\n",
      "947:\tlearn: 0.3955471\ttotal: 6.29s\tremaining: 345ms\n",
      "948:\tlearn: 0.3954701\ttotal: 6.3s\tremaining: 338ms\n",
      "949:\tlearn: 0.3953634\ttotal: 6.3s\tremaining: 332ms\n",
      "950:\tlearn: 0.3952074\ttotal: 6.31s\tremaining: 325ms\n",
      "951:\tlearn: 0.3951152\ttotal: 6.32s\tremaining: 319ms\n",
      "952:\tlearn: 0.3950365\ttotal: 6.33s\tremaining: 312ms\n",
      "953:\tlearn: 0.3949251\ttotal: 6.33s\tremaining: 305ms\n",
      "954:\tlearn: 0.3947781\ttotal: 6.34s\tremaining: 299ms\n",
      "955:\tlearn: 0.3946863\ttotal: 6.34s\tremaining: 292ms\n",
      "956:\tlearn: 0.3945670\ttotal: 6.35s\tremaining: 285ms\n",
      "957:\tlearn: 0.3944530\ttotal: 6.36s\tremaining: 279ms\n",
      "958:\tlearn: 0.3943318\ttotal: 6.36s\tremaining: 272ms\n",
      "959:\tlearn: 0.3941825\ttotal: 6.37s\tremaining: 265ms\n",
      "960:\tlearn: 0.3940919\ttotal: 6.38s\tremaining: 259ms\n",
      "961:\tlearn: 0.3940001\ttotal: 6.38s\tremaining: 252ms\n",
      "962:\tlearn: 0.3938991\ttotal: 6.39s\tremaining: 246ms\n",
      "963:\tlearn: 0.3938309\ttotal: 6.4s\tremaining: 239ms\n",
      "964:\tlearn: 0.3937115\ttotal: 6.41s\tremaining: 232ms\n",
      "965:\tlearn: 0.3936448\ttotal: 6.41s\tremaining: 226ms\n",
      "966:\tlearn: 0.3935334\ttotal: 6.42s\tremaining: 219ms\n",
      "967:\tlearn: 0.3934253\ttotal: 6.42s\tremaining: 212ms\n",
      "968:\tlearn: 0.3933306\ttotal: 6.43s\tremaining: 206ms\n",
      "969:\tlearn: 0.3932134\ttotal: 6.44s\tremaining: 199ms\n",
      "970:\tlearn: 0.3930717\ttotal: 6.44s\tremaining: 192ms\n",
      "971:\tlearn: 0.3929621\ttotal: 6.45s\tremaining: 186ms\n",
      "972:\tlearn: 0.3928618\ttotal: 6.46s\tremaining: 179ms\n",
      "973:\tlearn: 0.3927391\ttotal: 6.46s\tremaining: 173ms\n",
      "974:\tlearn: 0.3926401\ttotal: 6.47s\tremaining: 166ms\n",
      "975:\tlearn: 0.3925588\ttotal: 6.48s\tremaining: 159ms\n",
      "976:\tlearn: 0.3924209\ttotal: 6.48s\tremaining: 153ms\n",
      "977:\tlearn: 0.3923401\ttotal: 6.49s\tremaining: 146ms\n",
      "978:\tlearn: 0.3921517\ttotal: 6.5s\tremaining: 139ms\n",
      "979:\tlearn: 0.3919966\ttotal: 6.5s\tremaining: 133ms\n",
      "980:\tlearn: 0.3919018\ttotal: 6.51s\tremaining: 126ms\n",
      "981:\tlearn: 0.3918276\ttotal: 6.52s\tremaining: 119ms\n",
      "982:\tlearn: 0.3917172\ttotal: 6.53s\tremaining: 113ms\n",
      "983:\tlearn: 0.3916515\ttotal: 6.53s\tremaining: 106ms\n",
      "984:\tlearn: 0.3915363\ttotal: 6.54s\tremaining: 99.6ms\n",
      "985:\tlearn: 0.3914159\ttotal: 6.54s\tremaining: 92.9ms\n",
      "986:\tlearn: 0.3913218\ttotal: 6.55s\tremaining: 86.3ms\n",
      "987:\tlearn: 0.3911968\ttotal: 6.56s\tremaining: 79.6ms\n",
      "988:\tlearn: 0.3910781\ttotal: 6.56s\tremaining: 73ms\n",
      "989:\tlearn: 0.3909913\ttotal: 6.57s\tremaining: 66.4ms\n",
      "990:\tlearn: 0.3909041\ttotal: 6.58s\tremaining: 59.7ms\n",
      "991:\tlearn: 0.3908156\ttotal: 6.58s\tremaining: 53.1ms\n",
      "992:\tlearn: 0.3907461\ttotal: 6.59s\tremaining: 46.4ms\n",
      "993:\tlearn: 0.3906421\ttotal: 6.59s\tremaining: 39.8ms\n",
      "994:\tlearn: 0.3904849\ttotal: 6.6s\tremaining: 33.2ms\n",
      "995:\tlearn: 0.3904419\ttotal: 6.61s\tremaining: 26.5ms\n",
      "996:\tlearn: 0.3903825\ttotal: 6.61s\tremaining: 19.9ms\n",
      "997:\tlearn: 0.3902826\ttotal: 6.62s\tremaining: 13.3ms\n",
      "998:\tlearn: 0.3901377\ttotal: 6.63s\tremaining: 6.63ms\n",
      "999:\tlearn: 0.3900048\ttotal: 6.63s\tremaining: 0us\n",
      "Accuracy: 0.7868\n",
      "F1: 0.6948\n",
      "roc_auc: 0.5560\n"
     ]
    }
   ],
   "source": [
    "# Define CatBoost Model\n",
    "cb_model = CatBoostClassifier(random_state=42)\n",
    "\n",
    "# Train & Eval with function\n",
    "result = train_eval_non_scratch(cb_model, \"CatBoost\", X_train, X_test, y_train, y_test)\n",
    "eval_results = pd.concat([result, eval_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.786790</td>\n",
       "      <td>0.694814</td>\n",
       "      <td>0.555975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.786225</td>\n",
       "      <td>0.694531</td>\n",
       "      <td>0.550262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.771735</td>\n",
       "      <td>0.700464</td>\n",
       "      <td>0.536563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.787166</td>\n",
       "      <td>0.693944</td>\n",
       "      <td>0.541549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TabNet</td>\n",
       "      <td>0.787354</td>\n",
       "      <td>0.693681</td>\n",
       "      <td>0.582528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tab-Transformer</td>\n",
       "      <td>0.774746</td>\n",
       "      <td>0.698127</td>\n",
       "      <td>0.536956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NODE Classifier</td>\n",
       "      <td>0.697403</td>\n",
       "      <td>0.685480</td>\n",
       "      <td>0.514521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy        F1   ROC AUC\n",
       "0         CatBoost  0.786790  0.694814  0.555975\n",
       "3         LightGBM  0.786225  0.694531  0.550262\n",
       "4          XGBoost  0.771735  0.700464  0.536563\n",
       "5    Random Forest  0.787166  0.693944  0.541549\n",
       "6           TabNet  0.787354  0.693681  0.582528\n",
       "7  Tab-Transformer  0.774746  0.698127  0.536956\n",
       "8  NODE Classifier  0.697403  0.685480  0.514521"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
